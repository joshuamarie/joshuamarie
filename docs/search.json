[
  {
    "objectID": "services.html#consultation-firm",
    "href": "services.html#consultation-firm",
    "title": "Work with Me ‚Äî Consulting & Teaching",
    "section": "Consultation Firm",
    "text": "Consultation Firm\n\n\nWhat I Offer\nMathematics & statistics foundation\n\nCalculus\nLinear Algebra\nProbability and statistics theory\n\nStatistical modelling & Machine Learning 1\n\nStatistical inference and simulation\nBayesian inference with Stan/CmdStan\nCustom model development and validation\n\nStatistical modelling & Machine Learning 2\n\nExperimental design and causal inference\nLongitudinal study and time series analysis & forecasting\nApplications with Python and R\n\nResearch & Development Consultation\n\nResearch study consultation\n\n\n\nWhat I Offer\nData Science\n\nData Visualization ({ggplot2}, {altair})\nShiny app development\nData manipulation and relational algebra with SQL and {tidyverse}\nGeospatial data analysis\n\nPackage Development\n\nR/Python package development\nAPI design and documentation\nTesting frameworks\nOpen-source maintenance strategies\n\n\n\n\n\n\n\nRates, Inquiry & Engagement\n\n\nRetainer packages available for ongoing work\nBook the consultation firm in Calendly\nOr email me at: joshua.marie.k@gmail.com"
  },
  {
    "objectID": "services.html#course-tutorial",
    "href": "services.html#course-tutorial",
    "title": "Work with Me ‚Äî Consulting & Teaching",
    "section": "Course Tutorial",
    "text": "Course Tutorial\nThis is a live session with me, prepared with interactive slides.\n\nAvailable Now\nCore of R Programming\n\nCourse section 1: Functional programming\nCourse section 2: Performance optimization\nCourse section 3: Metaprogramming\n\n\n\nComing Soon\n\n\n\n\nBayesian Inference with Stan - Course section 1: Probabilistic programming fundamentals - Course section 2: Stan mechanics - Course section 3: Model building and diagnostics"
  },
  {
    "objectID": "services.html#products",
    "href": "services.html#products",
    "title": "Work with Me ‚Äî Consulting & Teaching",
    "section": "Products",
    "text": "Products\n\nNot available for now"
  },
  {
    "objectID": "posts/06-load-pkg/index.html",
    "href": "posts/06-load-pkg/index.html",
    "title": "Ways to load / attach packages in R",
    "section": "",
    "text": "Isn‚Äôt it great that R has more than 1 solution to load packages? Some of them are beautiful. Some of them should be illegal in at least three countries. Let‚Äôs rank them from ‚Äúplease never do this‚Äù to ‚Äúfinally, some good food.‚Äù\nIn this post, I will try enumerate the different ways to load packages in R, and discuss their pros and cons. I will also rank them from worst to best solution in practices."
  },
  {
    "objectID": "posts/06-load-pkg/index.html#base-use",
    "href": "posts/06-load-pkg/index.html#base-use",
    "title": "Ways to load / attach packages in R",
    "section": "\n1.1 The new base::use() function (v4.4.0+)",
    "text": "1.1 The new base::use() function (v4.4.0+)\nUpdate: When I discover the bug, thanks to u/guepier and his comment, this changes my mind. Now, I put this in the worst place amongst the solution I listed here.\nI feel like R Core saw the chaos and said ‚Äúfine, we‚Äôll do something‚Äù. This function is available in R version 4.4.0 and above, by the way.\nIt allows you to load packages in a way that minimizes namespace conflicts by only attaching the functions you explicitly use. Take note that base::use() is a short case of library(), a simple wrapper, where it keeps include.only and set:\n\n\nlib.loc to NULL\n\n\ncharacter.only to TRUE\n\n\nlogical.return to TRUE\n\n\nattach.required to FALSE\n\n\n\nuse('pkg', c('obj1', 'fun1'))\n\nThis is still library(), but granular imports are explicit. Except‚Ä¶\n\nAnother problem occurs: Remember, it is just a simple wrapper of library(), therefore the import still goes to the search path.\nIt‚Äôs like putting a fancy new paint job on a 1987 Honda Civic and calling it a Ferrari. It LOOKS different, but under the hood, same old engine, baby.\nFor example:\n\nmean_data = function(.data) {\n    use('dplyr', 'summarise')\n    use('tidyr', 'pivot_longer')\n    \n    summarise(\n        .data, across(\n            where(is.numeric), \n            \\(col) mean(col, na.rm = TRUE)\n        )\n    ) |&gt; \n        pivot_longer(\n            cols = where(is.numeric), \n            names_to = \"Variable\", \n            values_to = \"Ave\"\n        )\n}\n\nmean_data(iris)\n\n# A tibble: 4 √ó 2\n  Variable       Ave\n  &lt;chr&gt;        &lt;dbl&gt;\n1 Sepal.Length  5.84\n2 Sepal.Width   3.06\n3 Petal.Length  3.76\n4 Petal.Width   1.20\n\n\nAfter I execute mean_data(iris), the imports are accessible everywhere. EVERYWHERE!\nAnd base::use() is still broken even in the latest R versions.\nLike, it is so completely broken:\nuse('dplyr', 'mutate')\niris |&gt; mutate(Petal.Area = Petal.Length * Petal.Width)\n#&gt; Error in mutate(iris, Petal.Area = Petal.Length * Petal.Width) : \n#&gt;   could not find function \"mutate\"\n\nThe issue is that subsequent library() calls for an identical package are ignored, and the same is true for base::use(). Bananas. Completely broken.\n\n\n\n\n\n\n\nNote\n\n\n\nThis is noted by R core team:\n\nThis functionality is still experimental: interfaces may change in future versions."
  },
  {
    "objectID": "posts/06-load-pkg/index.html#require",
    "href": "posts/06-load-pkg/index.html#require",
    "title": "Ways to load / attach packages in R",
    "section": "\n1.2 Worst: Using require()\n",
    "text": "1.2 Worst: Using require()\n\n\n~Just‚Ä¶no. I‚Äôll be making a hot take here that sounds controversial, but this solution is the worst thing ever existed in R to attach the packages. ~\nUpdate: This solution may be bad, but at least not worse than base::use().\nThis function returns a Boolean value:\n\nrequire(pkg) |&gt; \n    suppressMessages() |&gt; \n    suppressWarnings() |&gt; \n    print()\n\n[1] FALSE\n\n\nIt returns TRUE if the package is successfully loaded and FALSE otherwise.\nAnd should only be applicable inside functions to check if a package is available.\n\ncheck_package = function() {\n    if (require(pkg, quietly = TRUE)) {\n        print(\"Package loaded successfully\")\n    } else {\n        print(\"Package not available\")\n    }\n}\ncheck_package()\n\n[1] \"Package not available\"\n\n\nUsing require() at the top of a script is how you get mysterious errors 50 lines later. Only acceptable inside functions when you actually check the return value.\nSeriously, this is just library() where you can place it at the top level of your script, but add another extra steps."
  },
  {
    "objectID": "posts/06-load-pkg/index.html#pacman",
    "href": "posts/06-load-pkg/index.html#pacman",
    "title": "Ways to load / attach packages in R",
    "section": "\n1.3 The pro boxer: {pacman}\n",
    "text": "1.3 The pro boxer: {pacman}\n\nThis guy will punch you to death. Just kidding, Manny Pacquiao is a great boxer :). The pacman package tries to streamline package management with functions like p_load().\nDo you know this?\nif (!require(pkg)) {\n    install.packages(\"pkg\")\n    library(pkg)\n}\nWell, they made a shortcut, with pacman::p_load():\npacman::p_load(pkg)\nYou can do the same as above, except you can do this for multiple packages.\nHere‚Äôs how:\npacman::p_load(pkg1, pkg2, pkg3)\nSounds convenient, right?\n\nActually mixes two completely different responsibilities:\n\nInstallation (one-time setup)\nLoading (analysis step)\n\nGreat for interactive playtime. Disastrous in scripts, packages, CI/CD, or any environment without internet. Also:\n\nIt violates the single responsibility principle, harder than a toddler with a drum kit.\n\nThis is like a pineapple pizza"
  },
  {
    "objectID": "posts/06-load-pkg/index.html#library-classic",
    "href": "posts/06-load-pkg/index.html#library-classic",
    "title": "Ways to load / attach packages in R",
    "section": "\n1.4 The classic library()\n",
    "text": "1.4 The classic library()\n\nSuch a classic function, isn‚Äôt it? After all, this is the most used function to attach R package namespace. It is a standard practice that most R users use, and it is safe: It will throw an error if pkg is not installed. This function is traditional and simple:\nlibrary(pkg)\nThat‚Äôs it, right?\nI hope it was that simple, but it has some serious downsides:\n\nIt attaches the entire package namespace to the search path,\nIt can lead to namespace clash, particularly if multiple packages have functions with the same name. This can make debugging difficult and lead to unexpected behaviors in your code.\nIt makes the imports unclear which functions come from which packages\nAll exported functions are available, even if you only need one or two\n\nTo detach the attached package namespace in the search path, use detach() function with package : keyword:\ndetach(package : pkg)\n\n\n\n\n\n\nWarning\n\n\n\nBe minded that library() function still potentially silently fails, even though it will throw an error, unlike require() where silent fails are always prominent."
  },
  {
    "objectID": "posts/06-load-pkg/index.html#combo-pack",
    "href": "posts/06-load-pkg/index.html#combo-pack",
    "title": "Ways to load / attach packages in R",
    "section": "\n1.5 library() and {conflicted} package combo",
    "text": "1.5 library() and {conflicted} package combo\nHow about forcing the search path to select / deselect the imports? Introducing conflicted package.\n\nIn this approach, I combine traditional library() with the conflicted package to explicitly handle namespace conflicts.\nHow good? For example, I prefer using dplyr::filter() over stats::filter(), but a bit later on, I want to use stats::filter() when I want to run time series. The conflicted::conflict_prefer() handles which you want to declare ‚Äúwinners‚Äù of conflicts.\nI‚Äôll make a scenario to make you understand:\n\n\nI have no use with stats::filter() because I only want to keep the data frame based on the condition using dplyr::filter(), and I want to load the entire dplyr namespace. Here, I declare dplyr::filter() as ‚Äúwinner‚Äù of the conflict:\n\nlibrary(dplyr)\n\nconflicted::conflict_prefer('filter', 'dplyr', 'stats')\nfilter(mtcars, cyl == 8)\n\n\n\nThen, I stopped using dplyr::filter() because I want to perform time series modelling with linear filtering using stats::filter(). Re-state stats::filter() as the ‚Äúwinner‚Äù of the conflict:\n\nconflicted::conflict_prefer('filter', 'stats', 'dplyr')\nfilter(1:10, rep(1, 3))\n\n\n\nStill loads everything. Still global. Still manual work. In my standard, this is actually good, but still not enough because it never allows granular imports and import aliasing, and besides, I‚Äôve had better."
  },
  {
    "objectID": "posts/06-load-pkg/index.html#double-colon",
    "href": "posts/06-load-pkg/index.html#double-colon",
    "title": "Ways to load / attach packages in R",
    "section": "\n1.6 Tedious but Explicit: The :: Operator",
    "text": "1.6 Tedious but Explicit: The :: Operator\n\nBefore packages like box and import introduced alternative import systems to R, the :: operator was (and still is) R‚Äôs built-in way to explicitly reference functions from specific namespaces without loading entire packages.\nThe :: operator is the most explicit base R solution for calling package functions. It‚Äôs part of R‚Äôs namespace system and requires no external dependencies - just base R.\nHere‚Äôs how:\n\nThe syntax is package::function(), which tells R exactly which package to pull the function from without attaching that package to your search path.\n\nMost of us using R are definitely using this (I am reusing an example from base::use):\n\nmean_data = function(.data) {\n    dplyr::summarise(\n        .data, across(\n            where(is.numeric), \n            \\(col) mean(col, na.rm = TRUE)\n        )\n    ) |&gt; \n        tidyr::pivot_longer(\n            cols = where(is.numeric), \n            names_to = \"Variable\", \n            values_to = \"Ave\"\n        )\n}\n\nmean_data(iris)\n\n# A tibble: 4 √ó 2\n  Variable       Ave\n  &lt;chr&gt;        &lt;dbl&gt;\n1 Sepal.Length  5.84\n2 Sepal.Width   3.06\n3 Petal.Length  3.76\n4 Petal.Width   1.20\n\n\n\n\n\n\n\n\nNotice\n\n\n\n\nNoticed that I don‚Äôt call dplyr:: for across() and where()? I have a blog talking about this.\n\n\n\nThis is great, compared to the previous solutions, no external packages needed and works mostly in any R version. The problem is this is way too verbose and repetitive, especially with many function calls:\nggplot2::ggplot(data, ggplot2::aes(date, y)) +\n    ggplot2::geom_point() + \n    ggplot2::geom_line() + \n    ggplot2::theme_minimal() + \n    ggplot2::labs(\n        x = \"Date (by month)\",\n        y = \"Value (in dollars)\", \n        title = \"Monthly Value in Dollar\"\n    )\nBeing typing-intensive is why I called this solution ‚Äútedious‚Äù.\n\nRespectable, but I bet nobody wants to type that many in 2025."
  },
  {
    "objectID": "posts/06-load-pkg/index.html#import-pack",
    "href": "posts/06-load-pkg/index.html#import-pack",
    "title": "Ways to load / attach packages in R",
    "section": "\n1.7 Second to best: {import} package",
    "text": "1.7 Second to best: {import} package\nIt is so close!\n\nThis package is made before box. So, before box, the import package is the best solution ever made, arrived to fix library()‚Äôs most egregious issues. Created by Stefan Milton Bache (of pipe fame), it brings selective imports to R without requiring a complete paradigm shift.\n\n\nFirst Example\nSymbol binding\n\n\n\nThe first example is simple: Normal imports with aliases.\n\nimport::from(\n    dplyr, \n    select, rename, keep_when = filter, mutate, summarise, n\n)\nimport::from(tidyr, long = pivot_longer, wide = pivot_wider, drop_na)\nimport::from(ggplot2, diamonds, cut_width)\n\ndiamonds |&gt; \n    keep_when(\n        cut %in% c(\"Ideal\", \"Premium\"), \n        carat &gt; 1\n    ) |&gt; \n    drop_na() |&gt; \n    mutate(\n        price_per_carat = price / carat,\n        size_category = cut_width(carat, 0.5)\n    ) |&gt; \n    select(carat, cut, color, price, price_per_carat, size_category) |&gt; \n    wide(\n        names_from = cut,\n        values_from = price_per_carat,\n        values_fn = median\n    ) |&gt; \n    summarise(\n        across(c(Ideal, Premium), \\(col) mean(col, na.rm = TRUE)),\n        n = n()\n    )\n\n# A tibble: 1 √ó 3\n  Ideal Premium     n\n  &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;\n1 6494.   5978.  9951\n\n\n\n\nUse backticks around %&gt;% since it is under non-syntactic names.\n\nimport::from(dplyr, select, filter, mutate, summarise, n, relocate)\nimport::from(magrittr, `%&gt;%`) \nimport::from(tidyr, long = pivot_longer, wide = pivot_wider, drop_na)\n\nmtcars %&gt;% \n    filter(cyl == 6) %&gt;% \n    mutate(\n        hp_per_cyl = hp / cyl,\n        efficiency = mpg / disp\n    ) %&gt;% \n    select(mpg, disp, hp, hp_per_cyl, efficiency, everything()) %&gt;% \n    summarise(\n        across(\n            c(mpg, hp_per_cyl, efficiency), \n            list(\n                mu = \\(x) mean(x, na.rm = TRUE), \n                sigma = \\(x) sd(x, na.rm = TRUE)\n            ), \n            .names = \"{.col}..{.fn}\"\n        ),\n        n = n()\n    ) %&gt;% \n    long(\n        cols = contains(c(\"mu\", \"sigma\")), \n        names_sep = \"\\\\..\", \n        names_to = c(\"Variable\", \"Stat\"), \n        values_to = \"Est\"\n    ) %&gt;% \n    wide(\n        names_from = Stat, \n        values_from = Est\n    ) %&gt;% \n    relocate(n, .after = last_col()) %&gt;%\n    mutate(\n        se = sigma / sqrt(n), \n        cv = sigma / mu\n    )\n\n# A tibble: 3 √ó 6\n  Variable       mu  sigma     n      se     cv\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 mpg        19.7   1.45       7 0.549   0.0736\n2 hp_per_cyl 20.4   4.04       7 1.53    0.198 \n3 efficiency  0.112 0.0231     7 0.00872 0.206 \n\n\n\n\n\nIt‚Äôs so awesome. Why?\n\nNo masking\nExplicit at the top\nWorks with roxygen2 (@importFrom)\nImports the pipe like any other function\n\nThere‚Äôs still some limitations. Even though import provide necessities that solves my problem in R‚Äôs import system -\n\n\nIt has no unifying solution to attach the imports in the current environment. In fact, import functions still attach imported functions to the parent environment (usually global). What I mean is that they‚Äôre not truly scoped to a module or function. Thus, the use of import::here():\n\nwith(iris, {\n    import::here(stats, corr = cor)\n\n    corr(Sepal.Length, Petal.Length)\n})\n\n[1] 0.8717538\n\n\nThe expression we made, with(iris, { ... }) creates a temporary environment that disappears immediately. So corr() is placed exactly there, inside that temporary environment, and you cannot reuse corr() somewhere in the environment, even in the global environment\ncorr(1:10, 2:11)\n#&gt; Error in corr(1:10, 2:11) : could not find function \"corr\"\nThis is better than loading entire packages, but not as clean as lexical scoping.\n\nThe package was designed primarily for CRAN packages. File-based modules feel like an afterthought rather than a first-class feature.\nIt lacks support for nested module hierarchies. You can import from files with this package, but you can‚Äôt organize modules into sophisticated directory structures with their own internal dependencies.\nUnlike box, there‚Äôs no way to import a whole package as an object without attaching names"
  },
  {
    "objectID": "posts/06-load-pkg/index.html#box",
    "href": "posts/06-load-pkg/index.html#box",
    "title": "Ways to load / attach packages in R",
    "section": "\n1.8 The ergonomically superior {box} package",
    "text": "1.8 The ergonomically superior {box} package\n\nFinally, some good food. \n\n\n\n\n\n\nMy impression\n\n\n\nIn 2021, Konrad Rudolph looked at R‚Äôs prehistoric import system, said:\n\n‚ÄúThis is rubbish‚Äù\n\nDisclaimer: I don‚Äôt know if he said it, I said this just for fun ;)\nI strongly agree. And then dropped one of the magnum opus: box ‚Äî he dropped it like Gordon Ramsay dropping a perfectly seared Wellington on the pass.\n\n\nThis isn‚Äôt ‚Äúslightly nicer imports‚Äù ‚Äî it‚Äôs a complete rethinking of how R package should be loaded, and R code should be organized and namespaced. It brings true module systems (like Python, JavaScript, or Ruby) to R.\nThere‚Äôs 4 of a kind to import like a sane person:\nbox::use(\n    purrr,                          # 1\n    tbl = tibble,                   # 2\n    dplyr = dplyr[filter, select],  # 3\n    stats[st_filter = filter, ...]  # 4\n)\n\nSource: https://github.com/klmr/box\n\n\n\nAttached the names? Nah, even better:\n\nImports the entire purrr package as an object.\n\nNothing goes into the search path.\n\nYou use it as purrr$map(), purrr$keep(), etc.\n\nZero risk of masking, zero pollution. Pure bliss.\n\n\n\nWhole package? But make it short\n\nSame vibe as 1, but you give the package a cute little nickname.\nNow you write tbl$tbl_df(), tbl$as_tibble(), etc.\n\nPerfect when you hate typing tibble:: but also hate global mess.\n\n\n\nI want the whole namespace‚Ä¶ but only some names in my face.\n\nA killer move, actually: import the whole package as an object, and selectively attach only the functions you actually want to write naked.\nSo your pipelines stay clean: filter(), select(), mutate() ‚Äî all smooth, drama-free.\n\nBut when you need the weird stuff, you still have the entire namespace sitting there like:\ndplyr$reconstruct_tibble_from_who_knows_what()\n\n\n\n\n‚ÄúI refuse to be gaslit by stats::filter() ever again.‚Äù\n\n‚ÄúI want everything from {stats} (because base R is already everywhere), but stats::filter() is a war criminal that keeps fighting with dplyr::filter().‚Äù\nSo basically, everything from {stats} is attached, but rename that one cursed function to st_filter() so it never bites me again.\nThe ... means ‚Äúeverything else, with their original names‚Äù.\n\n\n\nBut wait, there‚Äôs more!\nHere, watch the madness of how I apply box to load package deps:\nbox::use(\n    dplyr[\n        select, rename, \n        keep_when = filter,   # rename because we want to avoid needless fighting\n        mutate, summarise, \n        across, everything\n    ],\n    tidyr[pivot_longer, pivot_wider, drop_na],\n    magrittr[`%&gt;%`],          # yes, don't forget that the pipe is just another import\n    ggplot2[ggplot, aes, geom_point, theme_minimal, labs, ggsave],\n    lubridate[ymd, year, month, floor_date],\n    data.table[fread]         # because sometimes you need speed, not dignity\n)\nLess :: spam. No package::function() that makes your code look like it‚Äôs been hit by shrapnel. Zero library() / require().\nAnd then, the part that makes grown R programmers cry tears of joy ‚Äî You are also allowed to reuse exported namespace from an R script or a folder as a module.\nbox::use(\n    app/models/glm_fit[...],           # brings everything exported\n    app/plots/theme_pub[theme_pub],    # only the theme\n    app/utils/cleaning[clean_names, fix_dates],\n    ./secret_sauce                     # local folder / script = module\n)\nWith box, you can create modules that encapsulate your code and its dependencies ‚Äî another revolutionary and W move in R community. This package is making my life easier in managing and reuse code across different projects.\nThis approach aligns well with modern programming practices and helps to keep your codebase clean and maintainable.\n\n1.8.1 Little resources\nOther resources to learn more about this package:\n\nCRAN Index\nBox README\nMy book"
  },
  {
    "objectID": "posts/04-tidyselect-helpers/index.html",
    "href": "posts/04-tidyselect-helpers/index.html",
    "title": "The Hidden Magic of Tidy-Select: R‚Äôs Universal Column Selection Language",
    "section": "",
    "text": "1 Introduction\nHave you ever wondered how where(), starts_with(), and other selection helpers work seamlessly across different tidyverse packages? I recently discovered something surprising: you can actually use these functions in dplyr, tidyr, and other packages that invokes &lt;tidy-select&gt; API, without explicitly loading them.\nHere‚Äôs how it works:\n\niris |&gt; \n    tidyr::pivot_longer(\n        cols = where(is.numeric), # using `where()` w/out calling dplyr / tidyselect\n        names_to = 'Variable',\n        values_to = 'Measure'\n    )\n\n\n  \n\n\n\nTake note that I never load tidyselect and dplyr (the where() function in dplyr is just one of many re-exports). Yet, where() works perfectly. It doesn‚Äôt belong to / re-exported by tidyr, but you can use where(), if and only if the functions is invoking &lt;tidy-select&gt; API.\n\n2 What Are These Functions Called?\nThese are officially called tidyselect helpers (or ‚Äúselection language‚Äù). They‚Äôre part of the tidyselect package, which provides a domain-specific language (DSL) for selecting columns in data frames.\nYou might also hear them referred to as:\n\nSelection helper functions\n\n&lt;Tidy-select&gt; helpers\nColumn selection helpers\n\n3 The Complete Family of Selection Helpers\nThe tidyselect package can be divided into 3 categories of helpers.\n\n\nPattern Matching Helpers\nPredicate-Based Helpers\n‚ÄúPositional‚Äù Helpers\n\n\n\n\n\nColumns starting with a prefix\n\niris |&gt; \n    dplyr::select(starts_with(\"Sepal\")) |&gt; \n    head(3)\n\n\n  \n\n\n\n\n\nColumns ending with a suffix\n\niris |&gt; \n    dplyr::select(ends_with(\"Width\")) |&gt; \n    head(3)\n\n\n  \n\n\n\n\n\nColumns containing a literal string\n\niris |&gt; \n    dplyr::select(contains(\"al\")) |&gt; \n    head(3)\n\n\n  \n\n\n\n\n\nColumns matching a regular expression\n\niris |&gt; \n    dplyr::select(matches(\"^Sepal\")) |&gt; \n    head(3)\n\n\n  \n\n\n\n\n\nColumns following the number pattern\n\niris |&gt; \n    dplyr::select(num_range('x', 1:4)) |&gt; \n    head(3)\n\n\n  \n\n\n\n\n\n\n\nThe where() function is similar to SQL WHERE, except it is functional that (should) returns a Boolean value that satisfies the condition.\n\niris |&gt; \n    dplyr::select(where(is.numeric)) |&gt; \n    head(3)\n\n\n  \n\n\niris |&gt; \n    dplyr::select(where(is.factor)) |&gt; \n    head(3)\n\n\n  \n\n\niris |&gt; \n    dplyr::select(where(\\(col) is.numeric(col) && mean(col) &gt; 3.5))\n\n\n  \n\n\n\n\n\nThese are functions that select columns based on their position in the data frame\n\n\neverything()\n\niris |&gt; \n    dplyr::select(everything()) |&gt; \n    head(3)\n\n\n  \n\n\n\nThis is equivalent to relocate(iris, Species):\n\niris |&gt; \n    dplyr::select(Species, everything()) |&gt; \n    head(3)\n\n\n  \n\n\n\n\nlast_col()\n\n\niris |&gt; \n    dplyr::select(last_col()) |&gt; \n    head(3)\n\n\n  \n\n\n\nOffset: 2nd to the last\n\niris |&gt; \n    dplyr::select(last_col(1)) |&gt; \n    head(3)\n\n\n  \n\n\n\nOffset: Multiple columns from the end\n\niris |&gt; \n    dplyr::select(last_col(2):last_col()) |&gt; \n    head(3)\n\n\n  \n\n\n\n\n\n\nNoticed that I invoked most of &lt;tidy-select&gt; helpers, but never loaded dplyr or tidyselect, not once, just to use them.\n\n4 ‚ÄúData-Masking‚Äù Subset\nJust like those &lt;tidy-select&gt; helpers, some functions found in dplyr, but doesn‚Äôt in tidyselect. These are all the functions that can be used within ‚Äúdata-masking‚Äù functions, such as dplyr::mutate() and dplyr::summarise(). Take a note of the term ‚Äúwithin‚Äù, which means, you can‚Äôt use them outside from ‚Äúdata-masking‚Äù functions.\nI call across(), if_any(), and if_all() as projection helpers because they correspond to the SELECT clause in SQL, except they both if_any(), and if_all() map over the selected columns and returns the Boolean vector, while the across() function modifies the selected columns. The pick() function, on the other hand serves as a complement of across() by extracting them as a data frame, however, this only applies to subset a data frame to be invoked within the operations in ‚Äúdata-masking‚Äù functions. All of them can make use of the &lt;tidy-select&gt; API, meaning you can apply selectors like starts_with() or everything() to specify which columns to project.\n\n\nUsing pick()\nUsing across()\nUsing if_all() / if_any()\nFunctions you actually need to attach\n\n\n\nHere‚Äôs an example: Calculating mean and standard deviation\n\niris |&gt; \n    dplyr::group_by(Species) |&gt; \n    dplyr::summarise(\n        summary = list({\n            num = pick(where(is.numeric))\n            tibble::tibble(\n                vars = colnames(num), \n                mean = colMeans(num),\n                sd = apply(num, 2, sd)\n            )\n        })\n    ) |&gt; \n    tidyr::unnest(summary)\n\n\n  \n\n\n\n\nI am aware there‚Äôs a better approach to calculate the mean and standard deviation of each column by group.\n\n\n\nHere‚Äôs an example: Apply min-max normalization among numeric columns in iris dataset\n\niris |&gt; \n    dplyr::as_tibble() |&gt; \n    dplyr::mutate(\n        across(\n            where(is.numeric), \n            \\(col) { col - min(col) } / { max(col) - min(col) }\n        )\n    )\n\n\n  \n\n\n\nAnd once again, I never attach dplyr into the search path just to use across() and pick().\nYou can use across() in some dplyr ‚Äúdata-masking‚Äù function like filter(), but this is a deprecated behavior and attaching dplyr package is required.\n\n\nExample: Removing all missing values across all columns in airquality data frame\n\nairquality |&gt; \n    dplyr::filter(if_all(everything(), \\(col) !is.na(col))) |&gt; \n    head(5)\n\n\n  \n\n\n\nIf if_all() / if_any() is used outside filter(), those functions need dplyr package to be attached to use them.\n\n\nThough, there are some exceptions: there are helper functions you actually need dplyr to be attached to use them, otherwise they don‚Äôt work and R will throw an error.\nHere they are:\n\nlibrary(dplyr)\n\n\n\nn()\n\niris |&gt;\n    group_by(Species) |&gt; \n    slice_max(n = 20, order_by = Sepal.Length) |&gt; \n    summarise(\n        count = n(), # üëà \n        m_sl = mean(Sepal.Length)\n    )\n\n\n  \n\n\n\n\n\ncur_group()\n\nmtcars |&gt;\n    group_by(cyl) |&gt;\n    reframe({\n        model = lm(mpg ~ wt, data = cur_group()) # üëà \n        coefs = coef(model)\n\n        tibble(\n            terms = names(coefs), \n            estimate = coefs\n        )\n    })\n\n\n  \n\n\n\n\n\ncur_group_id()\n\nstarwars |&gt;\n    group_by(species) |&gt;\n    reframe(\n        species, \n        name, \n        hierarchical_id = sprintf(\"%02d-%03d\", cur_group_id(), row_number()) # üëà \n    ) |&gt; \n    slice_min(hierarchical_id, n = 15)\n\n\n  \n\n\n\n\n\ncur_group_rows()\n\niris |&gt; \n    group_by(Species) |&gt; \n    slice_sample(\n        n = 75, replace = TRUE\n    ) |&gt; \n    summarise(\n        m_sl = mean(Sepal.Length),\n        n = {length(cur_group_rows()) + 30} # üëà \n    )\n\n\n  \n\n\n\n\n\ncur_column()\n\niris |&gt; \n    as_tibble() |&gt; \n    transmute(\n        across(\n            where(is.numeric),\n            \\(col) {\n                if (stringr::str_detect(cur_column(), \"Sepal\")) { # üëà \n                    col - mean(col)\n                } else if (stringr::str_detect(cur_column(), \"Petal\")) { # üëà \n                    (col - mean(col)) / sd(col)\n                } else {\n                    col\n                }\n            }\n        )\n    )\n\n\n  \n\n\n\n\n\n\n\n\n\n5 Conclusion\nI hope they don‚Äôt change this soon, it is quite a nice feature (definitely not a bug üòã), assembling the DSL strengths across tidyverse APIs. Even if it is subtle. I still suggest you to attach these functions (through e.g.¬†library() and box::use()) for better maintainability."
  },
  {
    "objectID": "posts/02-arima-grid-search/index.html#introduction",
    "href": "posts/02-arima-grid-search/index.html#introduction",
    "title": "First level of time series modelling: Basic ARIMA model hyperparameter tuning and grid search in R",
    "section": "\n1.1 Introduction",
    "text": "1.1 Introduction\nThe ARIMA (AutoRegressive Integrated Moving Average) model is defined by three parameters:\n\n\np: Autoregressive order that counts the past lagged terms (This is AR in ARIMA context)\n\nd: Differencing order that counts the number of differencing to achieve stationarity (This is ‚ÄòI‚Äô or ‚Äúintegrate‚Äù in ARIMA context)\n\nq: Moving average order that counts the past error lagged terms (MA)\n\nChoosing the right combination of (p, d, q) is‚Ä¶not that easy, right when you want to achieve the best fit, even with Hyndman and Khandaka (2008) methodology with their forecast::auto.arima().\nThis is how it‚Äôs done:\n\nPrepare a time series data. I generate a time series data from this in order for you to replicate this.\n\nThen fit every possible ARIMA models across a grid of (p, d, q) values.\n\nThen evaluate the models performance by calculating the maximum log-likelihood then weight them with AIC (Akaike Information Criterion) and BIC (Bayesian Information Criterion).\n\nThen visualize the fitted values from every possible models, alongside the actual data.\n\nFrom the visual, highlight the best model in red.\n\nOptionally, you can make it interactive, using ‚Äòggiraph‚Äô, and I prepare it so that you can hover and explore model fits.\n\nThe packages used:\n\nbox (v1.2.0)\nggplot2 (v4.0.0)\nggiraph (v0.9.1)\npurrr (v1.0.2)\ndplyr (v1.1.4)\nforecast (v8.23.0)\nglue (v1.7.0)\ntidyr (v1.3.1)\nrlang (v1.1.4)\nscales (v1.4.0)"
  },
  {
    "objectID": "posts/02-arima-grid-search/index.html#simulating-data",
    "href": "posts/02-arima-grid-search/index.html#simulating-data",
    "title": "First level of time series modelling: Basic ARIMA model hyperparameter tuning and grid search in R",
    "section": "\n1.2 Simulating Data",
    "text": "1.2 Simulating Data\nWe generate a synthetic dataset with some trend and randomness:\n\nset.seed(123)\nts_sim = runif(365, 5, 10) + seq(-140, 224)^2 / 10000\nday = as.Date(\"2025-06-14\") - 0:364\n\nThis produces 365 daily observations with both trend and noise, which is a good test case for ARIMA."
  },
  {
    "objectID": "posts/02-arima-grid-search/index.html#fitting-multiple-arima-models",
    "href": "posts/02-arima-grid-search/index.html#fitting-multiple-arima-models",
    "title": "First level of time series modelling: Basic ARIMA model hyperparameter tuning and grid search in R",
    "section": "\n1.3 Fitting Multiple ARIMA Models",
    "text": "1.3 Fitting Multiple ARIMA Models\nWe test a grid of ARIMA parameters:\n\\[\n\\begin{aligned}\np &\\in \\{0,1,2\\} \\\\\nd &\\in \\{0,1\\} \\\\\nq &\\in \\{0,1,2\\}\n\\end{aligned}\n\\]\nWe exclude overly complex models where p + q &gt; 3.\n\nCodemodels = local({\n    box::use(\n        purrr[pmap, pmap_chr, possibly, map, map_dbl], \n        dplyr[transmute, mutate, filter, slice_min, slice, case_when], \n        forecast[Arima], \n        glue[glue], \n        tidyr[expand_grid], \n        rlang[exec]\n    )\n    \n    expand_grid(p = 0:2, d = 0:1, q = 0:2) |&gt; \n        transmute(\n            models = pmap_chr(\n                pick(1:3), \n                \\(p, d, q) glue(\"ARIMA({p},{d},{q})\")\n            ), \n            res = pmap(\n                pick(1:3),\n                possibly(\n                    function (p, d, q) {\n                        if (p + q &gt; 3) return(NULL)\n                        exec(Arima, as.ts(ts_sim), order = c(p, d, q))\n                    },\n                    otherwise = NULL\n                )\n            ), \n            fits = map(res, ~ if(is.null(.x)) NULL else fitted(.x)),\n            aic = map_dbl(res, ~ if(is.null(.x)) NA_real_ else AIC(.x)),\n            bic = map_dbl(res, ~ if(is.null(.x)) NA_real_ else BIC(.x))\n        ) |&gt; \n        filter(!is.na(aic)) |&gt;  # Remove failed models\n        mutate(\n            day = list(day),\n            is_lowest_aic = aic == min(aic, na.rm = TRUE),\n            is_lowest_bic = bic == min(bic, na.rm = TRUE)\n        )\n})\nmodels\n\n\n  \n\n\n\nThis gives us a nested data frame of fitted models with their AIC, BIC, and fitted values."
  },
  {
    "objectID": "posts/02-arima-grid-search/index.html#visualizing-models-with-ggplot2",
    "href": "posts/02-arima-grid-search/index.html#visualizing-models-with-ggplot2",
    "title": "First level of time series modelling: Basic ARIMA model hyperparameter tuning and grid search in R",
    "section": "\n1.4 Visualizing Models with ggplot2",
    "text": "1.4 Visualizing Models with ggplot2\nDo you want to visualize everything better, including the actual, fitted values, and highlight the fitted values made by the best fit?\nFrom models data, we just need the is_lowest_aic and is_lowest_bic. We just need to tweak the data a little bit here by expanding the fitted values with its corresponding data value. Then, set the model_type to condition the plotting data with dplyr::case_when().\n\nplot_data = local({\n    box::use(\n        tidyr[unnest], \n        dplyr[mutate, case_when]\n    )\n    models |&gt; \n        unnest(cols = c(day, fits)) |&gt;\n        mutate(\n            model_type = case_when(\n                is_lowest_aic ~ \"Best AIC\",\n                is_lowest_bic ~ \"Best BIC\", \n                TRUE ~ \"Other Models\"\n            )\n        )\n})\n\nOptionally:\n\n\nYou can put the information about the model which had the lowest AIC and BIC in an annotated box text in the plot.\n\nbest_model_1 = models |&gt; dplyr::filter(is_lowest_aic)\nbest_model_2 = models |&gt; dplyr::filter(is_lowest_bic)\n\n\n\nPointing out the maximum value of the time series data\n\nmax_val = max(ts_sim)\nmax_idx = which.max(ts_sim)\nmax_day = day[max_idx]\n\n\n\nThen, visualize:\n\nCodelocal({\n    box::use(\n        ggplot2[...],\n        scales[comma],\n        dplyr[filter], \n        glue[glue], \n    )\n    \n    p = ggplot() + \n        # Original data\n        geom_line(\n            aes(x = day, y = as.numeric(ts_sim)), \n            linewidth = 1.2, \n            color = \"#2C3E50\",\n            alpha = 0.8\n        ) + \n        geom_point(\n            aes(x = day, y = as.numeric(ts_sim)), \n            size = 0.8, \n            color = \"#2C3E50\", \n            alpha = 0.6\n        ) + \n        \n        # Other fitted models (light gray)\n        geom_line(\n            data = filter(plot_data, model_type == \"Other Models\"), \n            aes(x = day, y = fits, group = models), \n            color = '#BDC3C7',\n            alpha = 0.6,\n            linewidth = 0.5\n        ) + \n        \n        # Best BIC model (blue)\n        geom_line(\n            data = filter(plot_data, model_type == \"Best BIC\"), \n            aes(x = day, y = fits, group = models), \n            color = '#3498DB',\n            linewidth = 1.2,\n            alpha = 0.9\n        ) + \n        \n        # Best AIC model (red, on top)\n        geom_line(\n            data = filter(plot_data, model_type == \"Best AIC\"), \n            aes(x = day, y = fits, group = models), \n            color = '#E74C3C',\n            linewidth = 1.5,\n            alpha = 0.9\n        ) + \n        \n        # Peak annotation\n        annotate(\n            \"point\",\n            x = max_day, y = max_val,\n            size = 4, colour = \"#E74C3C\", shape = 21, stroke = 2, fill = \"white\"\n        ) + \n        annotate(\n            \"text\", \n            x = max_day + 25,\n            y = max_val + 0.5,\n            label = paste0(\"Peak: \", round(max_val, 1), \" sec\"), \n            color = \"#E74C3C\",\n            fontface = \"bold\",\n            size = 3.5\n        ) +\n        annotate(\n            \"curve\", \n            x = max_day + 20, xend = max_day + 0.1, \n            y = max_val + 0.3, yend = max_val, \n            linewidth = 0.8,\n            color = \"#E74C3C\", \n            curvature = -0.2,\n            arrow = arrow(length = unit(0.15, \"cm\"), type = \"closed\")\n        ) +\n        \n        # Model performance text box\n        annotate(\n            \"rect\",\n            xmin = min(day) + 20, xmax = min(day) + 100,\n            ymin = max(ts_sim) - 1.5, ymax = max(ts_sim) - 0.2,\n            fill = \"white\", color = \"#34495E\", alpha = 0.9\n        ) +\n        annotate(\n            \"text\",\n            x = min(day) + 60, y = max(ts_sim) - 0.5,\n            label = paste0(\"Best AIC: \", best_model_1$models, \n                           \"\\nAIC = \", round(best_model_1$aic, 1)),\n            color = \"#E74C3C\", fontface = \"bold\", size = 3.2\n        ) +\n        annotate(\n            \"text\",\n            x = min(day) + 60, y = max(ts_sim) - 1.1,\n            label = paste0(\"Best BIC: \", best_model_2$models,\n                           \"\\nBIC = \", round(best_model_2$bic, 1)),\n            color = \"#3498DB\", fontface = \"bold\", size = 3.2\n        ) +\n        \n        # Styling\n        scale_x_date(date_labels = \"%b %Y\", date_breaks = \"2 months\") +\n        scale_y_continuous(labels = comma) +\n        \n        labs(\n            x = \"Time Index\", \n            y = \"Simulated Response Values\", \n            title = \"ARIMA Model Grid Search: Simulated Time Series Analysis\",\n            subtitle = glue(\"Comparing {nrow(models)} successful ARIMA models ‚Ä¢ Best performing models highlighted\"),\n            caption = paste0(\"Models tested: p‚àà[0,2], d‚àà[0,1], q‚àà[0,2] ‚Ä¢ \",\n                             \"Original data shown in dark gray ‚Ä¢ \",\n                             \"Total observations: \", length(ts_sim))\n        ) + \n        \n        theme_minimal(base_size = 11, base_family = \"serif\") +\n        theme(\n            plot.title = element_text(\n                family = \"serif\", \n                colour = \"#2C3E50\",\n                size = 14,\n                face = \"bold\",\n                margin = margin(b = 5)\n            ),\n            plot.subtitle = element_text(\n                family = \"serif\",\n                colour = \"#7F8C8D\",\n                size = 10,\n                margin = margin(b = 15)\n            ),\n            plot.caption = element_text(\n                family = \"serif\",\n                colour = \"#95A5A6\",\n                size = 8,\n                margin = margin(t = 10)\n            ),\n            axis.text.x = element_text(\n                angle = 45, \n                hjust = 1,\n                margin = margin(t = 8),\n                color = \"#34495E\"\n            ), \n            axis.text.y = element_text(\n                margin = margin(r = 8),\n                color = \"#34495E\"\n            ), \n            axis.title = element_text(\n                color = \"#2C3E50\",\n                face = \"bold\"\n            ),\n            panel.grid.minor = element_blank(),\n            panel.grid.major = element_line(\n                color = \"#ECF0F1\", \n                linewidth = 0.3\n            ), \n            panel.background = element_rect(fill = \"#FEFEFE\", color = NA),\n            plot.background = element_rect(fill = \"white\", color = NA),\n            plot.margin = margin(20, 20, 20, 20)\n        ) \n    \n    p\n})\n\n\n\n\n\n\n\nWe visualize:\n\nOriginal data (dark gray)\nAll fitted values from every possible ARIMA model (light gray), except, the fitted values from the best fit is highlighted (red, blue, based on AIC, BIC, respectively)\nAnnotated peak point in the data\nAnnotated best AIC/BIC values"
  },
  {
    "objectID": "posts/02-arima-grid-search/index.html#optional-interactive-visualization-with-ggiraph",
    "href": "posts/02-arima-grid-search/index.html#optional-interactive-visualization-with-ggiraph",
    "title": "First level of time series modelling: Basic ARIMA model hyperparameter tuning and grid search in R",
    "section": "\n1.5 Optional: Interactive Visualization with ggiraph",
    "text": "1.5 Optional: Interactive Visualization with ggiraph\nIf you prefer your plot to be interactive like some figures in the website, use ‚Äòggiraph‚Äô interactive interface version of ggplot2, then girafe(). The output produced by girafe() is wrapped with HTML, so it can be run in web.\nI recommend ‚Äòggiraph‚Äô to build web applications in R.\nThis is the interactive version of the plot above:\n\nCodelocal({\n    box::use(\n        ggplot2[...],\n        scales[comma],\n        dplyr[filter, mutate, case_when], \n        glue[glue], \n        ggiraph[geom_line_interactive, geom_point_interactive, girafe, opts_hover, opts_hover_inv, opts_selection], \n        tidyr[unnest]\n    )\n    \n    # Use this for preparation\n    original_data = data.frame(\n        day = day,\n        ts_sim = ts_sim,\n        tooltip_line = \"actual data\",\n        tooltip_point = paste0(format(day, \"%Y-%m-%d\"), \"; readings: \", round(ts_sim, 1), \" secs\")\n    )\n    \n    plot_data = models |&gt; \n        unnest(cols = c(day, fits)) |&gt;\n        mutate(\n            model_type = case_when(\n                is_lowest_aic ~ \"Best AIC\",\n                is_lowest_bic ~ \"Best BIC\", \n                TRUE ~ \"Other Models\"\n            ),\n            # Create tooltip text for model lines\n            tooltip_text = case_when(\n                is_lowest_aic ~ paste0(\"best model: \", models, \"; AIC = \", round(aic, 2), \"; BIC = \", round(bic, 2)),\n                is_lowest_bic ~ paste0(\"best model: \", models, \"; AIC = \", round(aic, 2), \"; BIC = \", round(bic, 2)),\n                TRUE ~ paste0(\"model: \", models, \"; AIC = \", round(aic, 2), \"; BIC = \", round(bic, 2))\n            )\n        )\n  \n    p = ggplot() + \n        geom_line_interactive(\n            data = original_data,\n            aes(x = day, y = ts_sim, tooltip = tooltip_line, data_id = \"original_line\"), \n            linewidth = 1.2, \n            color = \"#2C3E50\",\n            alpha = 0.8\n        ) + \n        geom_point_interactive(\n            data = original_data,\n            aes(x = day, y = ts_sim, tooltip = tooltip_point), \n            size = 0.8, \n            color = \"#2C3E50\", \n            alpha = 0.6\n        ) + \n        \n        geom_line_interactive(\n            data = filter(plot_data, model_type == \"Other Models\"), \n            aes(x = day, y = fits, group = models, tooltip = tooltip_text, data_id = models), \n            color = '#BDC3C7',\n            alpha = 0.6,\n            linewidth = 0.5\n        ) + \n        \n        geom_line_interactive(\n            data = filter(plot_data, model_type == \"Best BIC\"), \n            aes(x = day, y = fits, group = models, tooltip = tooltip_text, data_id = models), \n            color = '#3498DB',\n            linewidth = 1.2,\n            alpha = 0.9\n        ) + \n        \n        geom_line_interactive(\n            data = filter(plot_data, model_type == \"Best AIC\"), \n            aes(x = day, y = fits, group = models, tooltip = tooltip_text, data_id = models), \n            color = '#E74C3C',\n            linewidth = 1.5,\n            alpha = 0.9\n        ) + \n        \n        scale_x_date(date_labels = \"%b %Y\", date_breaks = \"2 months\") +\n        scale_y_continuous(labels = comma) +\n        \n        labs(\n            x = \"Time Index\", \n            y = \"Simulated Response Values\", \n            title = \"ARIMA Model Grid Search: Simulated Time Series Analysis\",\n            subtitle = glue(\"Comparing {nrow(models)} successful ARIMA models ‚Ä¢ Best performing models highlighted\"),\n            caption = paste0(\"Models tested: p‚àà[0,2], d‚àà[0,1], q‚àà[0,2] ‚Ä¢ \",\n                             \"Original data shown in dark gray ‚Ä¢ \",\n                             \"Total observations: \", length(ts_sim))\n        ) + \n        \n        theme_minimal(base_size = 11, base_family = \"serif\") +\n        theme(\n            plot.title = element_text(\n                family = \"serif\", \n                colour = \"#2C3E50\",\n                size = 14,\n                face = \"bold\",\n                margin = margin(b = 5)\n            ),\n            plot.subtitle = element_text(\n                family = \"serif\",\n                colour = \"#7F8C8D\",\n                size = 10,\n                margin = margin(b = 15)\n            ),\n            plot.caption = element_text(\n                family = \"serif\",\n                colour = \"#95A5A6\",\n                size = 8,\n                margin = margin(t = 10)\n            ),\n            axis.text.x = element_text(\n                angle = 45, \n                hjust = 1,\n                margin = margin(t = 8),\n                color = \"#34495E\"\n            ), \n            axis.text.y = element_text(\n                margin = margin(r = 8),\n                color = \"#34495E\"\n            ), \n            axis.title = element_text(\n                color = \"#2C3E50\",\n                face = \"bold\"\n            ),\n            panel.grid.minor = element_blank(),\n            panel.grid.major = element_line(\n                color = \"#ECF0F1\", \n                linewidth = 0.3\n            ), \n            panel.background = element_rect(fill = \"#FEFEFE\", color = NA),\n            plot.background = element_rect(fill = \"white\", color = NA),\n            plot.margin = margin(20, 20, 20, 20)\n        ) \n    \n    interactive_plot = girafe(\n        ggobj = p,\n        options = list(\n            opts_hover(css = \"cursor:pointer;stroke-width:4;stroke-opacity:1;fill-opacity:1;r:4px;\"),\n            opts_hover_inv(css = \"opacity:0.1;\"),\n            opts_selection(type = \"none\")\n        )\n    )\n    \n    interactive_plot\n})"
  },
  {
    "objectID": "posts/02-arima-grid-search/index.html#disclaimer",
    "href": "posts/02-arima-grid-search/index.html#disclaimer",
    "title": "First level of time series modelling: Basic ARIMA model hyperparameter tuning and grid search in R",
    "section": "\n1.6 Disclaimer",
    "text": "1.6 Disclaimer\nThis is just a toy example of leveraging functional programming and basic hyperparameter tuning for time series in R, and some of my learning competencies about data visualization in R and how to get deeper in it.\nIf you are interested to learn more, check out my other gists."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My name is Joshua",
    "section": "",
    "text": "Computer Scientist ‚Ä¢ Statistician\n\n\nI am a computer scientist, package creator / maintainer / contributor (to R, Python, Julia), and a statistician. I studied multiple layers of programming paradigms and designs, and still actively learning. From what I studied so far, R and Python have closely equivalent feature parities, hence I use both for data science-y activities :). I write packages for statistics, data science, and numerical analysis, as my specialties found in those fields."
  },
  {
    "objectID": "index.html#joshua-marie",
    "href": "index.html#joshua-marie",
    "title": "My name is Joshua",
    "section": "",
    "text": "Computer Scientist ‚Ä¢ Statistician\n\n\nI am a computer scientist, package creator / maintainer / contributor (to R, Python, Julia), and a statistician. I studied multiple layers of programming paradigms and designs, and still actively learning. From what I studied so far, R and Python have closely equivalent feature parities, hence I use both for data science-y activities :). I write packages for statistics, data science, and numerical analysis, as my specialties found in those fields."
  },
  {
    "objectID": "index.html#recent-posts",
    "href": "index.html#recent-posts",
    "title": "My name is Joshua",
    "section": "Recent Posts",
    "text": "Recent Posts\n\n\n\n\n\n\n\n\n\n\nWays to load / attach packages in R\n\n\nWorst to best solution\n\n\n\nR\n\n\npackages\n\n\n\nA completely objective, totally scientific ranking (2025 edition)\n\n\n\n\n\nNov 17, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nHow much do you know about pipes?\n\n\nHistory and Functionality of pipes\n\n\n\nR\n\n\npipes\n\n\ntidyverse\n\n\nprogramming\n\n\n\n\n\n\n\n\n\nNov 10, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nThe Hidden Magic of Tidy-Select: R‚Äôs Universal Column Selection Language\n\n\nNot limited to tidyselect helpers\n\n\n\nR\n\n\ntidyselect\n\n\ntidyverse\n\n\n\n\n\n\n\n\n\nNov 3, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nBox: Placing module system into R\n\n\nDefinitive Guide\n\n\n\nR\n\n\nbook\n\n\n\n\n\n\n\n\n\nOct 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nFirst level of time series modelling: Basic ARIMA model hyperparameter tuning and grid search in R\n\n\nBasics of grid search for ARIMA with plots in R\n\n\n\nR\n\n\ntime-series\n\n\nmachine-learning\n\n\ngrid-search\n\n\n\n\n\n\n\n\n\nSep 27, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nAutomatically generate Deep Feedforward Neural Network (DFFNN) module from torch expression\n\n\nUse case of code generation in practice\n\n\n\nR\n\n\nmachine-learning\n\n\ntorch\n\n\npointless-code\n\n\n\n\n\n\n\n\n\nSep 23, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "contacts.html",
    "href": "contacts.html",
    "title": "Contact Me",
    "section": "",
    "text": "Email: joshua.marie.k@gmail.com\nGitHub: github.com/joshuamarie\nLinkedIn: linkedin.com/in/joshuamarie/"
  },
  {
    "objectID": "posts/01-meta-nn/index.html#introduction",
    "href": "posts/01-meta-nn/index.html#introduction",
    "title": "Automatically generate Deep Feedforward Neural Network (DFFNN) module from torch expression",
    "section": "\n1.1 Introduction",
    "text": "1.1 Introduction\nThe create_nn_module() function dynamically generates torch neural network module definitions. Instead of manually writing out layer definitions and forward pass logic, this function builds the code expressions for you.\nKey benefits:\n\n\nFlexibility: Change network architecture with a single function call\n\nAutomation: Generate multiple network configurations programmatically\n\nExperimentation: Quickly test different architectures in hyperparameter searches\n\nThis is how it‚Äôs done:\n\nDefine the network architecture (input size, hidden layers, output size)\nSpecify activation functions for each layer\nProgrammatically generate the initialize method (layer definitions)\nProgrammatically generate the forward method (forward pass logic)\nReturn an nn_module expression ready to be evaluated\n\nThe packages used:\n\n\nrlang (v1.1.4) - For metaprogramming tools\n\npurrr (v1.0.2) - For functional programming\n\nglue (v1.7.0) - For string interpolation\n\nmagrittr - For pipe operator\n\nbox (v1.2.0) - For modular code organization"
  },
  {
    "objectID": "posts/01-meta-nn/index.html#the-complete-function",
    "href": "posts/01-meta-nn/index.html#the-complete-function",
    "title": "Automatically generate Deep Feedforward Neural Network (DFFNN) module from torch expression",
    "section": "\n1.2 The Complete Function",
    "text": "1.2 The Complete Function\nI created create_nn_module() function a while ago and shared it on GitHub Gist. Here‚Äôs the function we‚Äôll be analyzing:\n\nCodecreate_nn_module = function(nn_name = \"DeepFFN\", hd_neurons = c(20, 30, 20, 15), no_x = 10, no_y = 1, activations = NULL) {\n    box::use(\n        rlang[new_function, call2, caller_env, expr, exprs, sym, is_function, env_get_list],\n        purrr[map, map2, reduce, set_names, compact, map_if, keep, map_lgl], \n        glue[glue], \n        magrittr[`%&gt;%`]\n    )\n    \n    nodes = c(no_x, hd_neurons, no_y)\n    n_layers = length(nodes) - 1\n    \n    call_args = match.call()\n    activation_arg = call_args$activations\n    \n    if (is.null(activations)) {\n        activations = c(rep(\"nnf_relu\", length(hd_neurons)), NA)\n    } else if (length(activations) == 1 || is.function(activations)) {\n        single_activation = activations\n        activations = c(rep(list(single_activation), length(hd_neurons)), list(NA))\n    }\n    \n    activations = map2(activations, seq_along(activations), function(x, i) {\n        if (is.null(x)) {\n            NULL\n        } else if (is.function(x)) {\n            if(!is.null(activation_arg) && is.call(activation_arg) && activation_arg[[1]] == quote(c)) {\n                func_name = as.character(activation_arg[[i + 1]])\n                sym(func_name)\n            } else if(!is.null(activation_arg) && (is.symbol(activation_arg) || is.character(activation_arg))) {\n                func_name = as.character(activation_arg)\n                sym(func_name)\n            } else {\n                parent_env = parent.frame()\n                env_names = ls(envir = parent_env)\n                matching_names = env_names %&gt;%\n                    keep(~ {\n                        obj = env_get_list(parent_env, .x)[[1]]\n                        identical(obj, x)\n                    })\n                \n                if (length(matching_names) &gt; 0) {\n                    sym(matching_names[1])\n                } else {\n                    stop(\"Could not determine function name for activation function\")\n                }\n            }\n        } else if (is.character(x)) {\n            if (length(x) == 1 && is.na(x)) {\n                NULL\n            } else {\n                sym(x)\n            }\n        } else if (is.symbol(x)) {\n            x\n        } else if (is.logical(x) && length(x) == 1 && is.na(x)) {\n            NULL\n        } else {\n            stop(\"Activation must be a function, string, symbol, NA, or NULL\")\n        }\n    })\n    \n    init_body = map2(1:n_layers, map2(nodes[-length(nodes)], nodes[-1], c), function(i, dims) {\n        layer_name = if (i == n_layers) \"out\" else glue(\"fc{i}\")\n        call2(\"=\", call2(\"$\", expr(self), sym(layer_name)), call2(\"nn_linear\", !!!dims))\n    })\n    \n    init = new_function(\n        args = list(), \n        body = call2(\"{\", !!!init_body)\n    )\n    \n    layer_calls = map(1:n_layers, function(i) {\n        layer_name = if (i == n_layers) \"out\" else glue(\"fc{i}\")\n        activation_fn = if (i &lt;= length(activations)) activations[[i]] else NULL\n        \n        result = list(call2(call2(\"$\", expr(self), sym(layer_name))))\n        if (!is.null(activation_fn)) {\n            result = append(result, list(call2(activation_fn)))\n        }\n        result\n    }) |&gt; \n        unlist() |&gt; # recursive = FALSE is also valid\n        compact()\n    \n    forward_body = reduce(layer_calls, function(acc, call) {\n        expr(!!acc %&gt;% !!call)\n    }, .init = expr(x))\n    \n    forward = new_function(\n        args = list(x = expr()), \n        body = call2(\"{\", forward_body)\n    )\n    \n    call2(\"nn_module\", nn_name, initialize = init, forward = forward)\n}\n\n\n\n\n1.2.1 Why box?\nYou‚Äôll notice that I‚Äôve been using another approach to load namespace in R. But, why ‚Äòbox‚Äô? You need to check out my mini book dedicated on modular programming in R.\n\n1.2.2 But why load dependencies using box::use() inside a function?\n\nWell, a function, or a function call, creates an environment, which encloses the objects and operations within it. In other words, we create a closure. This is actually a good practice for several reasons:\n\nNamespace isolation: Dependencies loaded inside the function will not make pollution the global environment, or conflicts with any packages loaded. When you load packages required with library(), inside a function or not, it attaches those packages to your search path, and will mask functions from other packages. With box::use() inside a function, the imports are scoped only to that function‚Äôs or call‚Äôs environment.\nExplicit dependencies: Anyone reading the function immediately knows what external tools it uses. You don‚Äôt have to scroll to the top of a script to see what‚Äôs loaded.\nReproducibility: The function becomes self-contained. If you share just this function, others know exactly what packages they need less hunting through documentation.\nAvoiding conflicts: Different functions can use different versions or implementations without conflicts. For example, one function might use dplyr::filter() while another uses stats::filter(), and they won‚Äôt interfere with each other.\nLazy loading: The packages are only loaded when the function is actually called, not when it‚Äôs defined. This can improve script startup time if you have many functions but only use a few.\n\n\n\n\n\n\n\nNote\n\n\n\nIn a nutshell: The ‚Äòbox‚Äô package provides explicit, granular imports, making it transparent which namespace to be imported from which packages. It‚Äôs like having a well-organized toolbox where each tool is labeled."
  },
  {
    "objectID": "posts/01-meta-nn/index.html#explanations",
    "href": "posts/01-meta-nn/index.html#explanations",
    "title": "Automatically generate Deep Feedforward Neural Network (DFFNN) module from torch expression",
    "section": "\n1.3 Explanations",
    "text": "1.3 Explanations\nI‚Äôll be trying to be concise on explaining each layers of the function so that you‚Äôll understand what I did\n\n1.3.1 Step 1: Loading Dependencies\nI use box::use() to load dependencies:\n\n\nrlang: Improvised Core R programming. One of the core R programming, metaprogramming which includes creating expressions and functions programmatically, are less painful than what base R have.\n\npurrr: Improvised Functional programming utilities.\n\nglue: R lacks Python‚Äôs f-string for string interpolation, although we have sprintf() and paste() for that. glue makes string interpolation more readable with glue(\"fc{i}\") instead of paste0(\"fc\", i) or sprintf(\"fc%d\", i).\n\nmagrittr: The pipe operator %&gt;% for chaining operations. This is optional, by the way ‚Äî R 4.1+ has the native pipe |&gt;, but %&gt;% offers better flexibility with the dot placeholder.\n\n1.3.2 Step 2: Defining Network Architecture\nIn DFFNN architecture, it is defined by the input layer, the hidden layer, and the output layer.\n\n\nSource: https://medium.com/data-science/designing-your-neural-networks-a5e4617027ed\n\nThe number of nodes are defined by integers, except for input and output layer nodes which they are fixed and determined by the data you provided, and they are defined by no_x and no_y. The number of hidden layers is defined by the length of input in hd_neurons argument.\nCombine no_x, hd_neurons, no_y in order:\nnodes = c(no_x, hd_neurons, no_y)\nAnd then calculate the length of nodes, which is \\(1 + n_{\\text{hidden layres}} + 1\\), and then subtract it by 1 because the applied activation functions is invoked between each layer.\nn_layers = length(nodes) - 1\n\n1.3.2.1 Example\nWhen you have:\n\n10 predictors\n\n5 hidden layers, and for each layer:\n\n20 nodes\n30 nodes\n20 nodes\n15 nodes\n20 nodes\n\n\n1 response variable\n\nTotal number of layers: 7\nThis means we need 7 - 1 linear transformations, and here is my diagram:\n\\[10_{\\text{inputs}} \\rightarrow20_{\\text{hd1}} \\rightarrow30_{\\text{hd2}} \\rightarrow20_{\\text{hd3}} \\rightarrow15_{\\text{hd4}} \\rightarrow20_{\\text{hd5}} \\rightarrow1_{\\text{ouput}}\\]\n\n1.3.3 Step 3: Setting Activation Functions\nThe activations argument holds the account of the activation function. It could be a string, a literal function, or a mix of it in a vector of inputs.\nThen, set activations = NULL, where NULL is the default value, which leads to set ReLU (nnf_relu) as the activation function for all hidden layers\n\nCodeif (is.null(activations)) {\n    activations = c(rep(\"nnf_relu\", length(hd_neurons)), NA)\n}\n\n\nEvery activations will have NA as the last element because we need to ensure no activation function after the output. The output layer often doesn‚Äôt need an activation (for regression) or needs a specific one based on the task (softmax for classification, sigmoid for binary classification). By defaulting to NA, the user can decide.\n\n\n\n\n\n\nLength of inputs\n\n\n\nTo provide values in activations argument, it needs to be equal to the size of hidden layers, or if you provide only 1 act. function, this will be the activation function across the transformations.\n\n\n\n\n\n\n\n\nDefault\n\n\n\nThe default is NULL. That is, if activations is not provided, the activation function is set to ReLU function.\n\n\n\n\n\n\n\n\nInstead of NULL\n\n\n\nNow, if you‚Äôre asking ‚ÄúWhy needs to set activations to \"nnf_relu\" instead of NULL‚Äù? Don‚Äôt worry, I did consider that, but this is just a pure demo.\n\n\n\n1.3.4 Step 4: Processing Activation Functions\nThis part (re)processes the activation function inputs in the activations argument. This kept tracks the argument you are putting, especially when you the input you are writing in activations argument has different types.\n\nCodecall_args = match.call()\nactivation_arg = call_args$activations\n\nactivations = map2(activations, seq_along(activations), function(x, i) {\n    if (is.null(x)) {\n        NULL\n    } else if (is.function(x)) {\n        if(!is.null(activation_arg) && is.call(activation_arg) && \n           activation_arg[[1]] == quote(c)) {\n            func_name = as.character(activation_arg[[i + 1]])\n            sym(func_name)\n        } else {\n            func_name = names(which(sapply(ls(envir = parent.frame()), \n                function(name) {\n                    identical(get(name, envir = parent.frame()), x)\n                })))[1]\n            if (!is.na(func_name)) {\n                sym(func_name)\n            } else {\n                stop(\"Could not determine function name for activation function\")\n            }\n        }\n    } else if (is.character(x)) {\n        if (length(x) == 1 && is.na(x)) {\n            NULL\n        } else {\n            sym(x)\n        }\n    } else if (is.symbol(x)) {\n        x\n    } else if (is.logical(x) && length(x) == 1 && is.na(x)) {\n        NULL\n    } else {\n        stop(\"Activation must be a function, string, symbol, NA, or NULL\")\n    }\n})\n\n\n\n1.3.5 Step 5: Building the initialize Method Body\nThe body I am referring in initialize method is the body of the function for the initialize implemented method. This part is a bit far from trivial. I named it init_body to keep track the expression I am trying to build.\n\n\n\n\n\n\nIn reality\n\n\n\nKeep in mind that there‚Äôs no initialize and forward parameters within nn_module() torch namespace or whatsoever. However, it is expected you to create them to create a module inside nn_module(). These parameters are kept within the ... wildcard parameter.\n\n\n\n1.3.5.1 Creation of the expressions inside the body\nHere is the part I am tracking inside create_nn_module body expression:\n\nCodeinit_body = map2(1:n_layers, map2(nodes[-length(nodes)], nodes[-1], c), \n    function(i, dims) {\n        layer_name = if (i == n_layers) \"out\" else glue(\"fc{i}\")\n        call2(\"=\", call2(\"$\", expr(self), sym(layer_name)), \n              call2(\"nn_linear\", !!!dims))\n    })\n\n\nWhat it does is it creates assignment expressions for each layer in the network.\nFor instance, c(20, 30, 20, 15, 20) is your argument for the activations:\n\n\nmap2(nodes[-length(nodes)], nodes[-1], c) pairs consecutive layer sizes:\n\nCodelist(\n    c(10, 20), \n    c(20, 30), \n    c(30, 20), \n    c(20, 15), \n    c(15, 20), \n    c(20, 1)\n)\n\n\n\n\nFor each pair, generates a layer assignment expression:\n\nLayer names: fc1, fc2, ‚Ä¶, out (last layer)\nCreates: self$fc1 = nn_linear(10, 20)\n\n\n\n\nThis will be the generated expression:\nself$fc1 = nn_linear(10, 20)\nself$fc2 = nn_linear(20, 30)\nself$fc3 = nn_linear(30, 20)\nself$fc4 = nn_linear(20, 15)\nself$fc5 = nn_linear(15, 20)\nself$out = nn_linear(20, 1)\n\n\n\n\n\n\nHow is it done?\n\n\n\nI need you to understand rlang::call2() a bit:\nThe call2() function is a glorified call() from base R that builds function call expressions.\nFrom what I did within init_body:\n\ncall2(\"$\", expr(self), sym(\"fc1\")) constructs self$fc1\n\ncall2(\"nn_linear\", !!!dims) is a bit complex:\n\nIt splices dims from what I created in map2(nodes[-length(nodes)], nodes[-1], c).\n\ncall2() function accepts rlang‚Äôs quasiquotation API, then splices the dimensions, i.e.¬†call2(\"nn_linear\", !!!c(10, 20)) to call2(\"nn_linear\", 10, 20).\nThen finally constructs nn_linear(10, 20)\n\n\n\ncall2(\"=\", lhs, rhs) parses an expression: lhs = rhs. This part yields an expression I want: self$fc1 = nn_linear(10, 20).\n\nNote: You can use &lt;- if you want, instead of =. After all, = within call2()‚Äôs .fn argument tokenize = as an assignment operator. \n\n\n\n1.3.5.2 Building an actual body and function\nNow, for this part:\n\nCodeinit = new_function(\n    args = list(), \n    body = call2(\"{\", !!!init_body)\n)\n\n\nDon‚Äôt forget to put curly brackets { around the built expression because it becomes necessary in R when composing a function with multiple lines. Still using call2() for that, particularly call2(\"{\", !!!init_body) creates a code block { ... } containing all initialization statements. The !!! operator ‚Äúsplices‚Äù the list of expressions into the block, because init_body forms a list of expressions.\nAfter building the expression I want for the body of initialize, let‚Äôs take further by utilizing it as a body to create a function with rlang::new_function. I just simply wraps all the layer initialization expressions into a complete function for initialize method for nn_module().\n\n\n\n\n\n\nInputs in initialize\n\n\n\nNotice that the argument for initialize is empty? I could‚Äôve place input_size and output_size if I wanted to, but it seems unnecessary since I already placed the sizes of the input and output within the expression I built. To make a function expression with empty arguments, place the args argument of new_function with empty list().\n\n\nHere‚Äôs the result:\nfunction() {\n    self$fc1 = nn_linear(10, 20)\n    self$fc2 = nn_linear(20, 30)\n    self$fc3 = nn_linear(30, 20)\n    self$fc4 = nn_linear(20, 15)\n    self$fc5 = nn_linear(15, 20)\n    self$out = nn_linear(20, 1)\n}\nStore this expression into init because we still have to finalize the expression we want to create. \n\n1.3.6 Step 6: Building Layer Calls for Forward Pass\nThe same process as initialize, except we are not building multiple lines of expression, just building a chained expression with ‚Äòmagrittr‚Äô pipe from the initial value.\n\n1.3.6.1 Creating layer of calls\nTo form this expression is also complex\n\nCodelayer_calls = map(1:n_layers, function(i) {\n    layer_name = if (i == n_layers) \"out\" else glue(\"fc{i}\")\n    activation_fn = if (i &lt;= length(activations)) activations[[i]] else NULL\n    \n    result = list(call2(call2(\"$\", expr(self), sym(layer_name))))\n    if (!is.null(activation_fn)) {\n        result = append(result, list(call2(activation_fn)))\n    }\n    result\n}) |&gt; \n    unlist() |&gt; \n    compact()\n\n\nWhat it does is it builds a sequence of operations for the forward pass: layer calls and their activation functions. I stored the output into layer_calls so that we can keep track of it.\nThe process:\n\n\nFor each layer, create a list containing:\n\nThe layer call: self$fc1()\n\nThe activation call (if exists): nnf_relu()\n\n\n\nFlatten all lists into a single sequence with unlist().\nFilter the list we created away from any NULL values with purrr::compact().\n\nThus, we form a list of expressions:\n\nCodelist(\n    self$fc1(), nnf_relu(),\n    self$fc2(), nnf_relu(),\n    self$fc3(), nnf_relu(),\n    self$fc4(), nnf_relu(),\n    self$fc5(), nnf_relu(),\n    self$out()\n)\n\n\nNote: The last layer (out) has no activation because we set it to NA.\n\n1.3.6.2 Building an actual body and function\nI choose to chain them, x or the input as the initial value, and choose not to break lines and forms multiple assignments. This is what I preferred, and besides, it‚Äôs so easy to form chained expression when the output is a defused call with reduce().\n\nCodeforward_body = reduce(layer_calls, function(acc, call) {\n    expr(!!acc %&gt;% !!call)\n}, .init = expr(x))\n\n\nI choose to chain all operations together with pipe operator %&gt;% from ‚Äòmagrittr‚Äô.\nThen, with reduce() works:\n\n\nStarting with x, it progressively adds each operation:\n\nStep 1: x %&gt;% self$fc1()\n\nStep 2: (x %&gt;% self$fc1()) %&gt;% nnf_relu()\n\nStep 3: (x %&gt;% self$fc1() %&gt;% nnf_relu()) %&gt;% self$fc2()\n\n‚Ä¶and so on\n\n\n\nAs for the final output:\nx %&gt;% self$fc1() %&gt;% nnf_relu() %&gt;% \n    self$fc2() %&gt;% nnf_relu() %&gt;% \n    self$fc3() %&gt;% nnf_relu() %&gt;% \n    self$fc4() %&gt;% nnf_relu() %&gt;% \n    self$fc5() %&gt;% nnf_relu() %&gt;% \n    self$out()\n\n\n\n\n\n\n\n\nWhy pipes?\n\n\n\nThe pipe operator makes the forward pass logic read like a natural sequence: ‚Äútake input x, pass through fc1, apply nnf_relu to invoke ReLU activation function, then pass through fc2, apply nnf_relu to invoke ReLU activation function, ‚Ä¶, it kepts repeating until we reach to out‚Äù\n\n\nAfter that, I stored it into forward_body, then make use of it to build the function for forward method with rlang::new_function():\n\nCodeforward = new_function(\n    args = list(x = expr()), \n    body = call2(\"{\", forward_body)\n)\n\n\nThe args for forward method has x with empty value. Then, wrap the piped forward pass into a function that accepts input x.\nAnd here‚Äôs the result:\nfunction(x) {\n    x %&gt;% self$fc1() %&gt;% nnf_relu() %&gt;% \n        self$fc2() %&gt;% nnf_relu() %&gt;% \n        self$fc3() %&gt;% nnf_relu() %&gt;% \n        self$fc4() %&gt;% nnf_relu() %&gt;% \n        self$fc5() %&gt;% nnf_relu() %&gt;% \n        self$out()\n}\nStore this expression into forward because we still have to finalize the expression we want to create. \n\n1.3.7 Step 7: Finalizing the nn_module Expression generation\nHere we are for the final part: generating the nn_module expression, by puzzling each part: initialize and forward.\nThe final part is built from this:\ncall2(\"nn_module\", nn_name, !!!set_names(list(init, forward), c(\"initialize\", \"forward\")))\nI mean, you still have to use call2() to build a call. The inputs should be:\n\n.fn = \"nn_module\" -&gt;\n\nThe rest of the arguments:\n\n\nnn_name which is equivalent to ‚ÄúDeepFFN‚Äù. You can set any names whatever you want, though.\ninitialize = init\nforward = forward\nOriginally, I formed this in this expression: !!!set_names(list(init, forward), c(\"initialize\", \"forward\")). But then, I realized that we only need initialize and forward, and besides, this is a bit overkill.\n\n\n\nThus, the final expression that defines the neural network module.\nAnd hence, I form a function that generates a, perhaps, template:\n\nhd_nodes = c(20, 30, 20, 15, 20)\nact_fns = c(\"nnf_relu\", \"nnf_relu\", \"nnf_relu\", \"nnf_relu\")\ncreate_nn_module(\n    hd_neurons = hd_nodes, \n    activations = act_fns\n)\n\nnn_module(\"DeepFFN\", initialize = function () \n{\n    self$fc1 = nn_linear(10, 20)\n    self$fc2 = nn_linear(20, 30)\n    self$fc3 = nn_linear(30, 20)\n    self$fc4 = nn_linear(20, 15)\n    self$fc5 = nn_linear(15, 20)\n    self$out = nn_linear(20, 1)\n}, forward = function (x) \n{\n    x %&gt;% self$fc1() %&gt;% nnf_relu() %&gt;% self$fc2() %&gt;% nnf_relu() %&gt;% \n        self$fc3() %&gt;% nnf_relu() %&gt;% self$fc4() %&gt;% nnf_relu() %&gt;% \n        self$fc5() %&gt;% self$out()\n})"
  },
  {
    "objectID": "posts/01-meta-nn/index.html#disclaimer",
    "href": "posts/01-meta-nn/index.html#disclaimer",
    "title": "Automatically generate Deep Feedforward Neural Network (DFFNN) module from torch expression",
    "section": "\n1.4 Disclaimer",
    "text": "1.4 Disclaimer\nThis is an advanced example of metaprogramming in R, demonstrating how to leverage functional programming and rlang for code generation. I don‚Äôt mind you to replicate what I did, but sometimes this technique should be used judiciously‚Äîsometimes simpler, more explicit code is better.\nThis example showcases:\n\nDeep understanding of R‚Äôs evaluation model\nFunctional programming with purrr\n\nExpression manipulation with rlang\n\nPractical application to deep learning workflows\n\nAnd also, I am aware to the fact that the function I made is ugly if you said so."
  },
  {
    "objectID": "posts/03-modules-in-r/index.html#what-youll-find-here",
    "href": "posts/03-modules-in-r/index.html#what-youll-find-here",
    "title": "Box: Placing module system into R",
    "section": "1.1 What You‚Äôll Find Here",
    "text": "1.1 What You‚Äôll Find Here\nA definitive guide that walks you through:\n\nAlternative approach to import R codes (i.e.¬†R packages, modules)\nModern approaches to compose and organize R codes\nStep-by-step tutorials for using the box package\nBest practices for maintainable R code"
  },
  {
    "objectID": "posts/03-modules-in-r/index.html#why-this-book",
    "href": "posts/03-modules-in-r/index.html#why-this-book",
    "title": "Box: Placing module system into R",
    "section": "1.2 Why this book",
    "text": "1.2 Why this book\nOnly little to no books teach you to correctly write reusable, composable, and modular R codes :). Most of the books maybe teaches you about R, particularly application of R in different fields, but little to none explains one of the best practices. Most of them uses library() anyways, so you won‚Äôt certainly find similar book like this.\nConsequently, while R offers various ways to organize code, the box package manages to be superior among them (I am bias) by introducing a fresh, modern approach to module system that may significantly improve your R development workflow, similar to the workflow made by other developers, particularly Python devs. This book bridges the gap between basic R programming and professional-grade code organization."
  },
  {
    "objectID": "posts/03-modules-in-r/index.html#how-to-use-this-guide",
    "href": "posts/03-modules-in-r/index.html#how-to-use-this-guide",
    "title": "Box: Placing module system into R",
    "section": "1.3 How to Use This Guide",
    "text": "1.3 How to Use This Guide\nClick here and it will send you to the actual book. \nThe content is structured progressively, building from foundational concepts to deep applications. For the best learning experience:\n\nStart with the introduction to understand the core concepts\nLearning the fundamentals of import system with {box} package\nLearning the structures and constructions of reusability of modules, treating them like R packages, and supplied with documentation\nLearning unit testing the modules"
  },
  {
    "objectID": "posts/03-modules-in-r/index.html#contributing",
    "href": "posts/03-modules-in-r/index.html#contributing",
    "title": "Box: Placing module system into R",
    "section": "1.4 Contributing",
    "text": "1.4 Contributing\nContributions are welcome! If you have suggestions or improvements, please open an issue or submit a pull request on the GitHub repository."
  },
  {
    "objectID": "posts/03-modules-in-r/index.html#license",
    "href": "posts/03-modules-in-r/index.html#license",
    "title": "Box: Placing module system into R",
    "section": "1.5 License",
    "text": "1.5 License\nThis book is licensed under the Creative Commons Attribution 4.0 International License (CC BY 4.0). See the LICENSE file for details."
  },
  {
    "objectID": "posts/03-modules-in-r/index.html#credits",
    "href": "posts/03-modules-in-r/index.html#credits",
    "title": "Box: Placing module system into R",
    "section": "1.6 Credits",
    "text": "1.6 Credits\nThis book was created by Joshua Marie.\nSpecial thanks to:\n\nKonrad Rudolph for creating and maintaining the box package\nThe R community for their continued support and feedback\n\nThe book is built with Quarto, hosted on GitHub Pages."
  },
  {
    "objectID": "posts/05-pipes/index.html#the-piper-pioneer-2013",
    "href": "posts/05-pipes/index.html#the-piper-pioneer-2013",
    "title": "How much do you know about pipes?",
    "section": "\n4.1 1. The {pipeR} Pioneer (2013)",
    "text": "4.1 1. The {pipeR} Pioneer (2013)\nThe pipeR package by Kun Ren was one of the earliest pipe implementations in R, introducing the %&gt;&gt;% operator.\n\nbox::use(pipeR[`%&gt;&gt;%`])\n\n1:10 %&gt;&gt;%\n    mean() %&gt;&gt;%\n    round(2)\n\n[1] 5.5\n\n\nHere‚Äôs the cool part:\n\nLambda expressions with parentheses:\n\n\n1:10 %&gt;&gt;%\n    (mean(.) * 2) %&gt;&gt;%\n    round(2)\n\n[1] 11\n\n\n\nSide effects with continued piping:\n\n\nset.seed(123)\nrnorm(100) %&gt;&gt;%\n    (~ plot(., main = \"Random Normal Values\")) %&gt;&gt;%  # Side effect\n    mean() %&gt;&gt;%\n    round(2)\n\n\n\n\n\n\n\n[1] 0.09\n\n\n\n\n\n\n\n\nWhy it faded\n\n\n\nIt‚Äôs not like it vanished from the existence, more like it is superseded by magrittr and took over."
  },
  {
    "objectID": "posts/05-pipes/index.html#the-game-changer-magrittr-pipe-2014",
    "href": "posts/05-pipes/index.html#the-game-changer-magrittr-pipe-2014",
    "title": "How much do you know about pipes?",
    "section": "\n4.2 2. The Game Changer: {magrittr} Pipe (2014)",
    "text": "4.2 2. The Game Changer: {magrittr} Pipe (2014)\nThe magrittr package, created by Stefan Milton Bache and later maintained by Lionel Henry at Posit (formerly RStudio), became the most popular pipe implementation. It was inspired by F#‚Äôs pipe-forward operator and Unix pipes.\n\nbox::use(magrittr[`%&gt;%`, `%&lt;&gt;%`, `%T&gt;%`, `%$%`, `%!&gt;%`])\n\nc(1, 2, 3, 4, 5) %&gt;%\n    mean() %&gt;%\n    round(2)\n\n[1] 3\n\n\nDo you know? There are plenty pipe operators in magrittr package, consists of at least 5 operators. Here are the special features:\n\n\nThe classic\nAssignment pipe\nTee pipe\nExposition pipe\nEager pipe\n\n\n\nThe %&gt;% is magrittr‚Äôs standard and ‚Äúlazy‚Äù pipe - it doesn‚Äôt evaluate arguments until needed, which can affect behavior with certain functions. Lazy evaluation means that the RHS is only computed when its value is required, which optimizes performance but can lead to surprises with side-effect-heavy code.\nTo understand better how %&gt;% works, let‚Äôs give a demonstration by applying dot placeholder for non-first arguments:\n\nmtcars %&gt;%\n    lm(mpg ~ cyl, data = .)\n\n\nCall:\nlm(formula = mpg ~ cyl, data = .)\n\nCoefficients:\n(Intercept)          cyl  \n     37.885       -2.876  \n\n\nThe dot (.) acts as a placeholder for the piped value, allowing it to be inserted into any argument position‚Äînot just the first. You can also apply multiple placeholders:\n\nmtcars %&gt;% \n    head(5) %&gt;% \n    split(., .$cyl)\n\n$`4`\n            mpg cyl disp hp drat   wt  qsec vs am gear carb\nDatsun 710 22.8   4  108 93 3.85 2.32 18.61  1  1    4    1\n\n$`6`\n                mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4      21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag  21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nHornet 4 Drive 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\n\n$`8`\n                   mpg cyl disp  hp drat   wt  qsec vs am gear carb\nHornet Sportabout 18.7   8  360 175 3.15 3.44 17.02  0  0    3    2\n\n\n\n\nThe %&lt;&gt;% operator is invoking reference semantics, where it pipes and assigns the result back to the original variable:\n\nx = 1:5\nx %&lt;&gt;% log() %&gt;% sum()\nx\n\n[1] 4.787492\n\n\nThis is equivalent to x = x %&gt;% log() %&gt;% sum() but more concise. What happened here is we created a side-effect of x. Some pointed it out why it is a problem.\n\n\nThe %T&gt;% ‚Äútee‚Äù pipe passes the left-hand side value forward, not the output of the right-hand side. Useful for side effects like plotting or printing, where you want to perform an action but continue with the original data:\n\nset.seed(123)\nrnorm(100) %T&gt;% \n    plot(main = \"Values before mean\") %&gt;% \n    mean() %&gt;%\n    round(2)\n\n\n\n\n\n\n\n[1] 0.09\n\n\nThis should be the equivalent:\n{\n    set.seed(123)\n    plot(rnorm(100), main = \"Values before mean\")\n    round(mean(rnorm(100)), 2)\n}\nSo, if you try the following:\n\n1:5 %T&gt;% \n    mean()\n\n[1] 1 2 3 4 5\n\n\nThe %T&gt;% operator discards the output of mean(1:5), and that‚Äôs because mean() doesn‚Äôt return a side-value effect.\nBy the way, the ‚Äútee‚Äù name comes from Unix‚Äôs tee command, which splits output streams.\n\n\nThe %$% ‚Äúexposition‚Äù pipe exposes the names within the left-hand side object to the right-hand side expression:\n\nmtcars %$%\n    cor(mpg, cyl)\n\n[1] -0.852162\n\n\nThis is equivalent to:\ncor(mtcars$mpg, mtcars$cyl)\nThis is particularly useful with functions that don‚Äôt have a data argument.\n\n\n\n\n\n\nWarning\n\n\n\nDo not use %$% operator when LHS is not a a list or data frame with named elements.\n\n\n\n\nThe %!&gt;% operator is the ‚Äúeager‚Äù version of %&gt;% that evaluates arguments immediately. This can matter for functions with non-standard evaluation:\n\n# Standard (lazy) pipe\niris %&gt;% \n    subset(Species == \"setosa\") %&gt;% \n    head(3)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n\n# Eager pipe (forces immediate evaluation)\niris %!&gt;% \n    subset(Species == \"setosa\") %!&gt;% \n    head(3)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n\n\nIn most cases, the difference is subtle, but it can matter for advanced programming.\nTo see the actual difference:\n\n\n%!&gt;%: cat(1) is immediately evaluated (it evaluates from left to right)\n\n\n0 %!&gt;% (\\(x) { cat(1); x }) %!&gt;% (\\(x) cat(2))\n\n12\n\n\n\n\n%&gt;%: Evaluates only cat(2) as the first result is never used\n\n\n0 %&gt;% (\\(x) { cat(1); x }) %&gt;% (\\(x) cat(2))  \n\n2\n\n\nSource: https://stackoverflow.com/questions/76326742/what-are-the-differences-and-use-cases-of-the-five-magrittr-pipes"
  },
  {
    "objectID": "posts/05-pipes/index.html#the-wrapr-dot-arrow-2017",
    "href": "posts/05-pipes/index.html#the-wrapr-dot-arrow-2017",
    "title": "How much do you know about pipes?",
    "section": "\n4.3 3. The {wrapr} Dot Arrow (2017)",
    "text": "4.3 3. The {wrapr} Dot Arrow (2017)\nJohn Mount‚Äôs wrapr package provides the %.&gt;% ‚Äúdot arrow‚Äù pipe, a deliberate and explicit alternative to %&gt;%.\n\nbox::use(wrapr[`%.&gt;%`])\n\n1:10 %.&gt;%\n    mean(.) %.&gt;%\n    round(., 2)\n\n[1] 5.5\n\n\nI don‚Äôt know much about this pipe, to be honest. As what I can see, this pipe requires the dot to always be explicit, which, for me, it‚Äôs so good that it can prevent some subtle bugs and makes code intentions clearer."
  },
  {
    "objectID": "posts/05-pipes/index.html#the-bizarro-pipe-base-r-2017",
    "href": "posts/05-pipes/index.html#the-bizarro-pipe-base-r-2017",
    "title": "How much do you know about pipes?",
    "section": "\n4.4 4. The Bizarro Pipe (Base R, ~2017)",
    "text": "4.4 4. The Bizarro Pipe (Base R, ~2017)\nI am not sure when this operator released, but there‚Äôs a pipe operator (not categorically) in base R: the ‚ÄúBizarro pipe‚Äù (-&gt;.;), that works like %&gt;% and %.&gt;%. It‚Äôs not a formal operator but an emergent behavior from combining existing R syntax.\n\n1:10 -&gt;.; \n    mean(.) -&gt;.; \n    round(., 2)\n\n[1] 5.5\n\n\nThe Bizarro pipe works by:\n\nUsing right assignment -&gt; to assign to . (this is done by typing - + &gt; + .)\nEnding each statement with ; to separate expressions\nThe next line uses . as input\n\nIt‚Äôs called ‚ÄúBizarro‚Äù because it uses right-to-left assignment syntax (-&gt;) to create a left-to-right workflow.\nHowever, it has disadvantages (talked in this Stackoverflow discussion):\n\nCreates hidden side-effects (the persistent . variable)\nGoes against R style guides (right assignment and semicolons are discouraged)\nCan lead to subtle bugs if you forget to assign to . at some step\nThe . variable is hidden from ls() and IDE inspectors\nIt‚Äôs so pesky, it won‚Äôt auto-indent\n\nSeriously, I won‚Äôt recommend Bizarro pipe at all. It is still a nice touch as a temporary replacement of %&gt;% for chained R codes, and will not use it for production code."
  },
  {
    "objectID": "posts/05-pipes/index.html#the-native-pipe-r-v4.1-2021",
    "href": "posts/05-pipes/index.html#the-native-pipe-r-v4.1-2021",
    "title": "How much do you know about pipes?",
    "section": "\n4.5 5. The Native Pipe (R v4.1+, 2021)",
    "text": "4.5 5. The Native Pipe (R v4.1+, 2021)\nIn May 2021, R v4.1 introduced the native pipe operator |&gt; (type | and &gt;), bringing pipe functionality into base R without the need for external packages. This operator is the actual operator that was inspired by the pipe-forward operator in F# and the concept of Unix pipes.\n\nc(1, 2, 3, 4, 5) |&gt;\n    mean() |&gt;\n    round(2)\n\n[1] 3\n\n\nThis is too identical to %&gt;% from magrittr with some obvious differences.\n\n4.5.1 Common differences from {magrittr} pipe\nThe placeholder for |&gt; is now applied in R v4.2 and above. For the syntax, it rather uses _, not ..\n\nmtcars |&gt;\n    lm(mpg ~ cyl, data = _)\n\n\nCall:\nlm(formula = mpg ~ cyl, data = mtcars)\n\nCoefficients:\n(Intercept)          cyl  \n     37.885       -2.876  \n\n\nThe native pipe:\n\nIs slightly faster (negligible in often cases, this matters for some cases like running for-loop)\nDoes not support the tee (%T&gt;%), exposition (%$%), or assignment (%&lt;&gt;%) operators\nCannot be used with compound assignment\nIs more strict about valid syntax\n\n4.5.2 Performance comparison\nThe native pipe is clearly faster than the magrittr pipe because native pipe does not add more function calls within its implementation compared to the magrittr pipe.\n\nbench::mark(\n    \"magrittr pipe\" = replicate(10000, 1:100 %&gt;% sum()), \n    \"native R pipe\" = replicate(10000, 1:100 |&gt; sum())\n)\n\n# A tibble: 2 √ó 6\n  expression         min   median `itr/sec` mem_alloc `gc/sec`\n  &lt;bch:expr&gt;    &lt;bch:tm&gt; &lt;bch:tm&gt;     &lt;dbl&gt; &lt;bch:byt&gt;    &lt;dbl&gt;\n1 magrittr pipe   49.6ms   53.5ms      18.7     375KB     65.4\n2 native R pipe   11.6ms   13.8ms      64.7     369KB     27.7\n\n\n\n4.5.3 Pipe-bind operator\nAfter R v4.2, the pipe-bind operator =&gt; (type = + &gt;), or a pipe-binding syntax, allows you to bind the result of the left-hand side (LHS) to a name within the right-hand side (RHS) expression.\nThis feature is, however, disabled by default. You may want to enable it by running the following:\n\nSys.setenv(\"_R_USE_PIPEBIND_\" = TRUE)\n\nAnother options:\n\nPlace this command into .Renviron file (Hint: run usethis::edit_r_environ()):\n\n_R_USE_PIPEBIND_=true\n\nRun this in a command prompt or PowerShell\n\nsetx _R_USE_PIPEBIND_ true\nIf you are in Linux / macOS (bash / zsh):\nexport _R_USE_PIPEBIND_=true\nThen restart R.\nHere‚Äôs what it does:\n\nmtcars |&gt; \n    df =&gt; lm(mpg ~ wt, data = df)\n\n\nCall:\nlm(formula = mpg ~ wt, data = df)\n\nCoefficients:\n(Intercept)           wt  \n     37.285       -5.344  \n\nmtcars |&gt; \n    df =&gt; split(df, df$cyl) |&gt; \n    lapply(\\(df) lm(mpg ~ wt, data = df)) |&gt; \n    vapply(\\(mod) summary(mod)$r.squared, numeric(1))\n\n        4         6         8 \n0.5086326 0.4645102 0.4229655 \n\n\nThe df name temporarily exists only inside that RHS expression ‚Äî not in your global environment. I like this because this is more explicit than . in %&gt;% operator. You can name the LHS result and refer to it directly inside the RHS expression anything you like."
  },
  {
    "objectID": "posts/05-pipes/index.html#non-pipe-alternatives",
    "href": "posts/05-pipes/index.html#non-pipe-alternatives",
    "title": "How much do you know about pipes?",
    "section": "\n4.6 Non-Pipe Alternatives",
    "text": "4.6 Non-Pipe Alternatives\nWhile the above are true pipe operators, it‚Äôs worth mentioning that some packages achieve similar left-to-right workflows through different mechanisms.\n\n4.6.1 Chaining in {data.table} (2010)\ndata.table uses method chaining with [][] notation. It is NOT a pipe operator in a sense, but achieves a similar left-to-right flow. It behaves differently from the pipe operator ‚Äî it chains operations within the same [.data.table method, and doesn‚Äôt pass values between functions, i.e.¬†the use of placeholders.\nLet‚Äôs look at the basic data.table example:\n\nbox::use(data.table[as.data.table, `:=`])\n\ndt = as.data.table(mtcars)\ndt[cyl == 8][order(-mpg)][, .(mpg, cyl, hp)][1:5]\n\n     mpg   cyl    hp\n   &lt;num&gt; &lt;num&gt; &lt;num&gt;\n1:  19.2     8   175\n2:  18.7     8   175\n3:  17.3     8   180\n4:  16.4     8   180\n5:  15.8     8   264\n\n\nDeeper method chaining in data.table with grouping and aggregation:\n\ndt[, log_mpg := log(mpg)][,\n    .(\n        mpg_mean = mean(mpg, na.rm = TRUE), \n        log_mpg_mean = mean(log_mpg, na.rm = TRUE)\n    ), by = cyl\n][\n    order(-mpg_mean, -log_mpg_mean)\n]\n\n     cyl mpg_mean log_mpg_mean\n   &lt;num&gt;    &lt;num&gt;        &lt;num&gt;\n1:     4 26.66364     3.270454\n2:     6 19.74286     2.980439\n3:     8 15.10000     2.700171\n\n\nThis is method chaining, not piping‚Äîthe key difference is that pipes pass values between different functions, while data.table chains operations within the same [ method.\n\n4.6.2 Multiple Assignment with {zeallot} (2018)\nThis is not exactly an operator that behaves like a pipe, where it passes LHS as an input for RHS, but I would like to point this one out. R lacks destructuring (also called ‚Äúunpacking‚Äù) method, just like what you see in other languages, such as Python:\nx, y = 0, 1\nThe zeallot allows destructuring assignment with %&lt;-%. While not exactly a pipe operator to chain the commands, works well in pipe-like workflows.\n\nbox::use(zeallot[`%&lt;-%`])\n\n# Multiple assignment\nc(a, b) %&lt;-% c(1, 2)\nc(a, b)\n\n[1] 1 2\n\n\nDestructuring with computations:\n\nc(mean_val, sd_val, n) %&lt;-% local ({\n    set.seed(125)\n    x = rnorm(100)\n    c(mean(x), sd(x), length(x))\n})\n\ncat(glue::glue(\"Mean: {mean_val}, SD: {sd_val} , N: {n}\"), \"\\n\")\n\nMean: 0.100208694251594, SD: 1.06105719788861 , N: 100 \n\n\nWorks with pipe workflows:\n\nset.seed(123)\nc(m, s) %&lt;-% (rnorm(100) %&gt;% { c(mean(.), sd(.)) })\nc(m, s)\n\n[1] 0.09040591 0.91281588"
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Check out my blogs",
    "section": "",
    "text": "Get notified when I publish new posts. No spam, unsubscribe anytime"
  },
  {
    "objectID": "posts/index.html#subscribe-to-my-newsletter",
    "href": "posts/index.html#subscribe-to-my-newsletter",
    "title": "Check out my blogs",
    "section": "",
    "text": "Get notified when I publish new posts. No spam, unsubscribe anytime"
  }
]