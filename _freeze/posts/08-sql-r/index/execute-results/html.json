{
  "hash": "e466534fa1bf4fe7df45f8c9287fc984",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Why SQL + R is an affable combo when I start learning SQL?\"\ndate: \"2025-11-28\"\nimage: \"image.png\"\ncategories: [R, SQL, data-science, analytics]\ndescription: \"Learn mastering both — and how to make them work together seamlessly.\"\nformat:\n    html:\n        toc: true\n        toc-float: true\n        toc-depth: 3\n        number-sections: true\n        code-fold: false\n        code-tools: false\n        theme: default\n        highlight-style: tango\n        fig-width: 10\n        fig-height: 6\n        fig-cap-location: bottom\n        code-annotations: hover\nexecute:\n    echo: true\n    warning: false\n    message: false\nfilters:\n    - social-share\nshare:\n    permalink: \"https://joshuamarie.com/posts/08-sql-r\"\n    description: \"Why SQL + R is an affable combo when I start learning SQL? — Joshua Marie\"\n    twitter: true\n    facebook: true\n    reddit: true\n    stumble: true\n    tumblr: true\n    linkedin: true\n    email: true\n    mastodon: true\n    bsky: true\n    location: \"before-body\"\nengine: knitr\n---\n\n## Introduction\n\nI am already using R since 2018, and uses SQL since around 2022-2023. Way back in 2023, I am learning one of the most valuable feature in R, and that's the ability to integrate R into other software. That's because I only use softwares independently, i.e. R only, Python only, etc. This is how I first learn SQL, and I learn few frameworks that integrates R and SQL databases. \n\nIf you've spent any time in data science, I am sure you encountered language wars and such debates — there's like hundreds or maybe thousands of blogs spread in the community comparing which languages is better or worse. I am not talking about that in this blog post, however, here's the thing — it's not really a versus situation. SQL and R are like peanut butter and jelly. Each is good on its own, but why not both? *Flavorful*. \n\n<!-- ![](why-not-both.gif) -->\n\nRegardless, SQL excels at what databases do best: storing, organizing, and retrieving massive amounts of data with lightning speed. R, on the other hand, shines where creativity and complexity matter: statistical modeling, advanced visualizations, and transforming raw data into insights that actually mean something. \n\nIn this post, I'll show you why combo-ing R and SQL isn't just nice to have — it's my stack. And more importantly, I'll show you what I know how to make them work together so seamlessly you'll wonder how you ever worked any other way.\n\n## Why Learn SQL Through R?\n\nBefore we dive into the technical details, let me explain why R is actually a fantastic environment for learning SQL:\n\n1.  Immediate Feedback Loop\n\n    When you're learning SQL in a traditional database environment, you often need to set up servers, configure connections, and deal with authentication. With R, you can start writing queries in seconds and see results immediately in your familiar R environment.\n\n2.  Best of Both Worlds\n\n    You can write pure SQL when you want to practice, or use `{dplyr}` syntax and see the generated SQL. This dual approach accelerates learning because you can:\n    \n    -   Write `{dplyr}` code and inspect the SQL it produces\n    -   Compare your hand-written SQL with `{dbplyr}`'s output\n    -   Gradually transition from `{dplyr}` comfort to SQL mastery\n\n3.  Visualization Integration\n\n    The moment you query data, you can pipe it directly into `{ggplot2}` or other R visualization tools. No export/import cycles, no switching between applications—just seamless analysis.\n\n4.  Reproducible Workflows  \n\n    Everything lives in a script or R Markdown document. Your queries, analysis, and visualizations are all version-controlled and reproducible.\n\n## Tools and Packages\n\nI can name few tools and packages on working with SQL databases in R, most especially when you just started. I don't have any database in my own device, but did you know you can simulate databases? These are the tools and packages to start:\n\n1.  `{tidyverse}` — Why this? This is a package that holds the complete set of tools in data science, and that includes working with databases. Speaking of which, this is a *meta-package* that also contains what we need: `{dbplyr}`, which also contains `{DBI}` package dependency. \n2.  `{box}` — I already talked about this package in my previous blog posts. Please, take a look at them if you have some time:\n\n    - [Box: Placing module system into R](https://joshuamarie.com/posts/03-modules-in-r/)\n    - [In my \"Ways to load / attach packages in R\" blog post ](https://joshuamarie.com/posts/06-load-pkg/#box)\n\n3.  `{dbplyr}` — This is the magic translator. It converts your familiar `{dplyr}` code into SQL queries behind the scenes. You write R, it speaks SQL to the database. The best part? You can inspect the SQL it generates, which makes it a fantastic learning tool.\n4.  `{DBI}` — Think of this as the universal adapter for database connections. It provides a consistent interface whether you're connecting to SQLite, PostgreSQL, MySQL, or other databases. It handles the connection, sending queries, and fetching results.\n5.  `{RSQLite}` — This is the R interface to SQLite databases. SQLite is perfect for learning because it's lightweight, requires no server setup, and the entire database is just a single file on your computer.\n\nInstall them through this:\n\n::: panel-tabset\n\n### Native R\n\n``` r\ninstall.packages(c('tidyverse', 'box', 'RSQLite'))\n```\n\n### Using **{pak}**\n\nInstall them directly\n\n``` r\npak::pak(c(\n    'tidyverse', \n    'box', \n    'RSQLite'\n))\n```\n\nWhen you preferred the development version\n\n``` r\npak::pak(c(\n    \"tidyverse/tidyverse\", \n    \"klmr/box\", \n    \"r-dbi/RSQLite\"\n))\n```\n\n:::\n\n## With existing database\n\nI learn SQL thanks to SQLite. This is a language-agnostic library, written in C, that acts like a database while being lightweight. You can use it literally everywhere! It is also used to built into everywhere, it could be mobile phones and most computers. \n\nThanks to SQLite, I made a first move to learn SQL without installing heavy softwares, such as PostgreSQL and MySQL, just to learn SQL. Additionally, SQLite is an open-source, but not open for contribution (I believe this is designed for good purpose). \n\n### Why SQLite is Perfect for Learning\n\nHere's why SQLite is the ideal training ground:\n\n- **No server required** — It's just a file on your computer\n- **Zero configuration** — No ports, users, or permissions to set up\n- **Lightweight** — Databases can be megabytes instead of gigabytes\n- **Production-ready** — Despite being \"lite,\" it's used in production by major applications\n- **SQL standard** — You learn real SQL that transfers to other databases\n\nIn a positive sense, R and SQL is a great combo. Maybe R and SQL is not a great combo for software development as Python and SQL combo, R and SQL can make a place in data analysis instead. As long as you have `{DBI}` and `{RSQLite}` installed in your R, you can now make a first move on integrating R and SQL, and you're good to go. \n\n### SQLite in R\n\nOh, you can definitely learn SQL and R at the same time, considering that SQLite is portable and lightweight. The only primary requirements are `{DBI}` and `{RSQLite}`. If you know how to write a query, you don't need a compatible set of packages in `{tidyverse}` and `{dbplyr}`, otherwise, as long as you know how to use `{tidyverse}` packages, namely `{dplyr}`, `{tidyr}`, etc., you can use it instead. \n\nLet me show you how to connect to a SQLite database and work with it:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nbox::use(\n    DBI[dbConnect, dbWriteTable, dbDisconnect], \n    RSQLite[SQLite]\n)\n\n# <1>\ncon = dbConnect(SQLite(), \"first_database.sqlite\")\n\n# <2>\ndf = data.frame(\n    id = 1:5,\n    name = c(\"Alice\", \"Bob\", \"Charlie\", \"Diana\", \"Eve\"),\n    age = c(25, 30, 35, 28, 42),\n    city = c(\"New York\", \"London\", \"Tokyo\", \"Paris\", \"Sydney\")\n)\n\n# <3>\ndbWriteTable(\n    con, \n    \"customers\",\n    df, \n    overwrite = TRUE\n)\n```\n:::\n\n\n1.  Create a connection (this creates the database file if it doesn't exist)\n2.  Create some sample data\n3.  Write the data as a *table* to the database \n\n::: {.callout-note title=\"Explanation\" collapse=\"true\"}\n\n1.  Create a connection (this creates the database file if it doesn't exist)\n2.  Create some sample data\n3.  Write the data as a *table* to the database \n:::\n\n**What just happened?**  \nWe created a SQLite database file called `first_database.sqlite` in your working directory. Inside it, we created a table called `customers` with our sample data. If the file already exists, R simply connects to it.\n\n### Two Ways to Query: Pure SQL vs {dplyr}\n\nNow comes the fun part—you can query this database in two different ways, and each has its benefits for learning.\n\n:::: panel-tabset\n\n#### Just SQL\n\nDid you know that with `{knitr}`, you can write SQL code chunks directly in your R Markdown or Quarto documents? This is incredibly handy for mixing SQL queries with your data analysis in R.\n\n```` \n```\\{sql connection=con\\}\nSELECT name, age, city \nFROM customers \nWHERE age > 30\n```\n````\n\n> Kindly remove the `\\` when you copy the code chunk above.\n\nAlright, I wrote the SQL code chunk above again here for your reference:\n\n\n::: {.cell}\n\n```{.sql .cell-code}\nSELECT name, age, city \nFROM customers \nWHERE age > 30\n```\n\n\n<div class=\"knitsql-table\">\n\n\nTable: 2 records\n\n|name    | age|city   |\n|:-------|---:|:------|\n|Charlie |  35|Tokyo  |\n|Eve     |  42|Sydney |\n\n</div>\n:::\n\n\nOr you can store the query into a string, and send it via `DBI::dbSendQuery()`, placed in `statement` argument. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nDBI::dbSendQuery(\n    con, \n    \"SELECT name, age, city \\nFROM customers \\nWHERE age > 30\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<SQLiteResult>\n  SQL  SELECT name, age, city \nFROM customers \nWHERE age > 30\n  ROWS Fetched: 0 [incomplete]\n       Changed: 0\n```\n\n\n:::\n:::\n\n\n**Why this matters for learning:**  \nYou're writing actual SQL. No training wheels. This builds muscle memory for SQL syntax and helps you think in terms of SQL operations: SELECT, FROM, WHERE, JOIN, GROUP BY, etc.\n\n#### **{dplyr}** API\n\nNothing can make it so easy to work with databases using a familiar syntax with `{dplyr}`. Yes, with `{dbplyr}`, you can use `{dplyr}` functions to interact with your database tables as if they were regular data frames in R. Here's how you can perform the same query using `{dplyr}`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbox::use(\n    dplyr[filter, select, tbl, collect, show_query]\n)\n\ncustomers_tbl = tbl(con, \"customers\")\n\nout = customers_tbl |> \n    filter(age > 30) |> \n    select(name, age, city)\n\nout |> collect()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 3\n  name      age city  \n  <chr>   <dbl> <chr> \n1 Charlie    35 Tokyo \n2 Eve        42 Sydney\n```\n\n\n:::\n:::\n\n\n**The magic behind this:**  \n\nWhen you use `{dplyr}` verbs on a database table, `{dbplyr}` doesn't immediately execute anything. It's lazy! It builds up the query and only executes it when you call `collect()`. This is efficient because:\n\n-   You can chain many operations without multiple round-trips to the database\n-   Only the final result set gets pulled into R memory\n-   The heavy computation happens in the database where it's optimized\n\n**See the generated SQL:**  \n\nHow about getting the SQL query generated by `{dbplyr}`? You can use the `show_query()` function to see the SQL that `{dbplyr}` generates for your `{dplyr}` code:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nout |> \n    show_query()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<SQL>\nSELECT `name`, `age`, `city`\nFROM `customers`\nWHERE (`age` > 30.0)\n```\n\n\n:::\n:::\n\n\nEasy, right? If you know R already, treat it as your SQL teacher! Write familiar `{dplyr}` code, then check the SQL translation. Over time, you'll start to intuitively understand how `filter()` becomes `WHERE`, how `select()` becomes `SELECT`, and how more complex operations translate to SQL.\n\n::::\n\n### Working with Query Results\n\nOnce you have query results, you can treat them like any R data frame:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nbox::use(\n    ggplot2[ggplot, aes, geom_col, theme_minimal, labs]\n)\n\n# 1 \nresult_data = collect(out)\n\n# 2 \nresult_data |>  \n    ggplot(aes(x = name, y = age, fill = city)) +\n    geom_col() +\n    theme_minimal() +\n    labs(\n        title = \"Customers Over 30\",\n        x = \"Name\",\n        y = \"Age\"\n    )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n\n::: {.callout-note title=\"Explanation\" collapse=\"true\"}\n\n1.  Retrieve the data\n2.  Now you can analyze it with R\n:::\n\nThis is where the R + SQL combination really shines. You use SQL's efficiency to get exactly the data you need, then R's rich ecosystem for analysis and visualization.\n\n### Database Hygiene\n\nAlways remember to close your database connections once you're done:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbDisconnect(con)\n```\n:::\n\n\nThis releases resources and ensures your database file isn't locked. In practice, connections are also closed automatically when your R session ends, but it's good practice to do it explicitly.\n\n## Learning SQL in R without a server\n\nBut I know some of you wants to know what it looks like to use the existing database and then call it in R. \n\nI literally said in the introduction that you can *simulate* — I have another different meaning: \n\n    -   Use `simulate_*` family functions in `{dbplyr}` package. These functions allow you to create in-memory database tables that mimic real database behavior without needing an actual database server. This is perfect for learning and testing SQL queries in R.\n\n### What Are Simulated Connections?\n\nSimulated connections create an in-memory representation of how different database systems handle SQL. This means you can:\n\n-   See how your `{dplyr}` code translates to different SQL dialects\n-   Learn SQL without any database installation\n-   Test queries before running them on production databases\n-   Understand the quirks of different database systems\n\n### Demonstration: Simulating Microsoft SQL Server\n\nFirst, let me show you how it looks like to connect to a database, i.e. SQLite in this case, and work with it. Try imagine you have a SQL server, and you want to connect to it using R. Use `simulate_mssql()` function to simulate a Microsoft SQL Server database connection:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbox::use(\n    dbplyr[simulate_mssql, tbl_lazy]\n)\n\ncon_sim = simulate_mssql()\n\ncustomers_sim = tbl_lazy(df, con_sim)\ncustomers_sim |> \n    select(name, age, city) |> \n    filter(age > 30)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<SQL>\nSELECT `name`, `age`, `city`\nFROM `df`\nWHERE (`age` > 30.0)\n```\n\n\n:::\n:::\n\n\nWe are performing a pure lazy evaluation in this step\n\n## Conclusion\n\nSQL and R aren't competitors—they're collaborators. SQL is your data retrieval expert, getting you exactly the data you need with incredible efficiency. R is your analysis specialist, turning that data into insights, models, and visualizations.\n\nThe data scientists who succeed are the ones who can speak both languages fluently. They use SQL to ask databases the right questions, and R to find the answers that matter.\n\nSo don't pick sides. Master both. Your future self (and your future employers) will thank you.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}